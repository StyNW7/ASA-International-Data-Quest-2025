{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa22beb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1. TENTUKAN NAMA FILE DAN PARAMETER ---\n",
    "\n",
    "# Ganti ini dengan nama file CSV kamu yang sebenarnya\n",
    "file_wdi = 'WDICSV-rev.csv'\n",
    "file_hdi = 'human-development-index-(hdi)-by-country-2025.csv'\n",
    "file_suicide = 'suicide-rate-by-country-2025.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "975eec35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semua file berhasil dibaca.\n",
      "Memproses data WDI...\n",
      "Data WDI selesai diproses.\n",
      "Memproses data HDI...\n",
      "Data HDI selesai diproses.\n",
      "Memproses data Suicide Rate...\n",
      "Data Suicide Rate selesai diproses.\n"
     ]
    }
   ],
   "source": [
    "# Indikator WDI yang ingin kamu ambil (berdasarkan chat sebelumnya)\n",
    "wdi_indicators_to_keep = [\n",
    "    'SP.POP.0014.TO.ZS', # Populasi 0-14\n",
    "    'SP.POP.1564.TO.ZS', # Populasi 15-64\n",
    "    'SP.POP.65UP.TO.ZS'  # Populasi 65+\n",
    "    'SL.UEM.TOTL.ZS'     # <-- INDIKATOR BARU: Unemployment Total\n",
    "]\n",
    "\n",
    "# Rentang tahun utama untuk analisis\n",
    "# (Meskipun data suicide hanya 2019-2021, kita ambil rentang lebih luas dulu)\n",
    "years_to_keep = [2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "# --- 2. MEMBACA SEMUA FILE ---\n",
    "try:\n",
    "    df_wdi_raw = pd.read_csv(file_wdi)\n",
    "    df_hdi_raw = pd.read_csv(file_hdi)\n",
    "    df_suicide_raw = pd.read_csv(file_suicide)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File tidak ditemukan. Pastikan nama file sudah benar.\")\n",
    "    print(e)\n",
    "    # Hentikan eksekusi jika file tidak ada\n",
    "    exit()\n",
    "\n",
    "print(\"Semua file berhasil dibaca.\")\n",
    "\n",
    "# --- 3. PROSES DATA WDICSV ---\n",
    "print(\"Memproses data WDI...\")\n",
    "\n",
    "# 3.1. Filter hanya indikator yang kita butuhkan\n",
    "df_wdi_filtered = df_wdi_raw[df_wdi_raw['Indicator Code'].isin(wdi_indicators_to_keep)].copy()\n",
    "\n",
    "# 3.2. Melt data WDI\n",
    "# Kolom identitas (ID)\n",
    "id_vars_wdi = ['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code']\n",
    "# Kolom nilai (tahun) - ambil semua kolom selain ID\n",
    "value_vars_wdi = [col for col in df_wdi_filtered.columns if col not in id_vars_wdi]\n",
    "\n",
    "df_wdi_melted = df_wdi_filtered.melt(id_vars=id_vars_wdi,\n",
    "                                   value_vars=value_vars_wdi,\n",
    "                                   var_name='Year',\n",
    "                                   value_name='Value')\n",
    "\n",
    "# 3.3. Bersihkan dan filter tahun\n",
    "df_wdi_melted['Year'] = pd.to_numeric(df_wdi_melted['Year'], errors='coerce')\n",
    "df_wdi_melted = df_wdi_melted.dropna(subset=['Year']) # Hapus jika 'Year' bukan angka\n",
    "df_wdi_melted['Year'] = df_wdi_melted['Year'].astype(int)\n",
    "df_wdi_melted = df_wdi_melted[df_wdi_melted['Year'].isin(years_to_keep)]\n",
    "\n",
    "# 3.4. Pivot data WDI agar indikator menjadi kolom\n",
    "# Ini mengubah 'Indicator Code' dari baris menjadi kolom\n",
    "df_wdi_processed = df_wdi_melted.pivot_table(index=['Country Name', 'Year'],\n",
    "                                           columns='Indicator Code',\n",
    "                                           values='Value').reset_index()\n",
    "df_wdi_processed.columns.name = None # Menghapus nama indeks kolom\n",
    "\n",
    "print(\"Data WDI selesai diproses.\")\n",
    "\n",
    "# --- 4. PROSES DATA HDI ---\n",
    "print(\"Memproses data HDI...\")\n",
    "\n",
    "# 4.1. Tentukan kolom HDI yang akan di-melt\n",
    "hdi_cols_to_melt = [\n",
    "    'HumanDevelopmentIndex_2019',\n",
    "    'HumanDevelopmentIndex_2020',\n",
    "    'HumanDevelopmentIndex_2021',\n",
    "    'HumanDevelopmentIndex_2022',\n",
    "    'HumanDevelopmentIndex_2023'\n",
    "]\n",
    "# Filter hanya kolom yang ada di file\n",
    "hdi_cols_exist = [col for col in hdi_cols_to_melt if col in df_hdi_raw.columns]\n",
    "\n",
    "# 4.2. Melt data HDI\n",
    "df_hdi_melted = df_hdi_raw.melt(id_vars=['country'],\n",
    "                                value_vars=hdi_cols_exist,\n",
    "                                var_name='Indicator',\n",
    "                                value_name='HDI')\n",
    "\n",
    "# 4.3. Ekstrak tahun dari 'Indicator'\n",
    "df_hdi_melted['Year'] = df_hdi_melted['Indicator'].str.extract(r'(\\d{4})')\n",
    "df_hdi_melted['Year'] = pd.to_numeric(df_hdi_melted['Year']).astype(int)\n",
    "\n",
    "# 4.4. Siapkan untuk merge (ganti nama kolom & pilih kolom)\n",
    "df_hdi_processed = df_hdi_melted.rename(columns={'country': 'Country Name'})\n",
    "df_hdi_processed = df_hdi_processed[['Country Name', 'Year', 'HDI']]\n",
    "\n",
    "print(\"Data HDI selesai diproses.\")\n",
    "\n",
    "# --- 5. PROSES DATA SUICIDE RATE ---\n",
    "print(\"Memproses data Suicide Rate...\")\n",
    "\n",
    "# 5.1. Tentukan kolom Suicide Rate yang akan di-melt (HANYA YANG UMUM)\n",
    "suicide_cols_to_melt = [\n",
    "    'SuicideRateCountries_2019',\n",
    "    'SuicideRateCountries_2020',\n",
    "    'SuicideRateCountries_2021'\n",
    "    # Tambahkan 'SuicideRateCountries_2022' jika ada di file-mu\n",
    "]\n",
    "# Filter hanya kolom yang ada di file\n",
    "suicide_cols_exist = [col for col in suicide_cols_to_melt if col in df_suicide_raw.columns]\n",
    "\n",
    "# 5.2. Melt data Suicide Rate\n",
    "df_suicide_melted = df_suicide_raw.melt(id_vars=['country'],\n",
    "                                        value_vars=suicide_cols_exist,\n",
    "                                        var_name='Indicator',\n",
    "                                        value_name='Suicide Rate')\n",
    "\n",
    "# 5.3. Ekstrak tahun\n",
    "df_suicide_melted['Year'] = df_suicide_melted['Indicator'].str.extract(r'(\\d{4})')\n",
    "df_suicide_melted['Year'] = pd.to_numeric(df_suicide_melted['Year']).astype(int)\n",
    "\n",
    "# 5.4. Siapkan untuk merge\n",
    "df_suicide_processed = df_suicide_melted.rename(columns={'country': 'Country Name'})\n",
    "df_suicide_processed = df_suicide_processed[['Country Name', 'Year', 'Suicide Rate']]\n",
    "\n",
    "print(\"Data Suicide Rate selesai diproses.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4647eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menggabungkan semua data...\n",
      "Data berhasil digabungkan.\n",
      "\n",
      "--- SELESAI ---\n",
      "Data gabungan berhasil disimpan ke: dataset_gabungan_final.csv\n",
      "\n",
      "5 baris pertama data gabungan:\n",
      "                  Country Name  Year  SP.POP.0014.TO.ZS  SP.POP.1564.TO.ZS  \\\n",
      "0                  Afghanistan  2019          44.576832          53.047015   \n",
      "1                  Afghanistan  2020          44.224104          53.405162   \n",
      "2                  Afghanistan  2021          43.908125          53.739325   \n",
      "5  Africa Eastern and Southern  2019          41.666633          55.176225   \n",
      "6  Africa Eastern and Southern  2020          41.381733          55.426098   \n",
      "\n",
      "     HDI  Suicide Rate  \n",
      "0  0.492          4.10  \n",
      "1  0.488          3.63  \n",
      "2  0.473          3.60  \n",
      "5    NaN           NaN  \n",
      "6    NaN           NaN  \n",
      "\n",
      "Informasi data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 885 entries, 0 to 1468\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Country Name       885 non-null    object \n",
      " 1   Year               885 non-null    int64  \n",
      " 2   SP.POP.0014.TO.ZS  795 non-null    float64\n",
      " 3   SP.POP.1564.TO.ZS  795 non-null    float64\n",
      " 4   HDI                573 non-null    float64\n",
      " 5   Suicide Rate       588 non-null    float64\n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 48.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# --- 6. GABUNGKAN (MERGE) SEMUA DATA ---\n",
    "print(\"Menggabungkan semua data...\")\n",
    "\n",
    "# 6.1. Mulai dengan data WDI\n",
    "df_merged = df_wdi_processed.copy()\n",
    "\n",
    "# 6.2. Merge dengan HDI\n",
    "# 'how=outer' berarti kita menyimpan semua data, meskipun ada tahun/negara yang\n",
    "# tidak cocok di kedua dataset.\n",
    "df_merged = pd.merge(df_merged, df_hdi_processed, on=['Country Name', 'Year'], how='outer')\n",
    "\n",
    "# 6.3. Merge dengan Suicide Rate\n",
    "df_merged = pd.merge(df_merged, df_suicide_processed, on=['Country Name', 'Year'], how='outer')\n",
    "\n",
    "print(\"Data berhasil digabungkan.\")\n",
    "\n",
    "# --- 7. FINALISASI DATA ---\n",
    "\n",
    "# 7.1. Filter rentang tahun akhir\n",
    "# Analisis gabungan (HDI vs Suicide) hanya bisa dilakukan untuk tahun 2019-2021\n",
    "# karena data suicide rate-mu (berdasarkan list kolom) hanya sampai 2021.\n",
    "# Jika kamu punya data suicide 2022, ubah ini.\n",
    "analysis_years = [2019, 2020, 2021]\n",
    "df_final = df_merged[df_merged['Year'].isin(analysis_years)].copy()\n",
    "\n",
    "# 7.2. Hapus baris yang semua datanya kosong (kecuali Country & Year)\n",
    "data_cols = [col for col in df_final.columns if col not in ['Country Name', 'Year']]\n",
    "df_final = df_final.dropna(subset=data_cols, how='all')\n",
    "\n",
    "# 7.3. Simpan ke file CSV baru\n",
    "output_file = 'dataset_gabungan_final.csv'\n",
    "df_final.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"\\n--- SELESAI ---\")\n",
    "print(f\"Data gabungan berhasil disimpan ke: {output_file}\")\n",
    "print(\"\\n5 baris pertama data gabungan:\")\n",
    "print(df_final.head())\n",
    "print(\"\\nInformasi data:\")\n",
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01a49332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting altair\n",
      "  Using cached altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair) (4.25.1)\n",
      "Collecting narwhals>=1.14.2 (from altair)\n",
      "  Using cached narwhals-2.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair) (25.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair) (4.15.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair) (0.28.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jinja2->altair) (3.0.3)\n",
      "Using cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "Using cached narwhals-2.9.0-py3-none-any.whl (422 kB)\n",
      "Installing collected packages: narwhals, altair\n",
      "\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   -------------------- ------------------- 1/2 [altair]\n",
      "   -------------------- ------------------- 1/2 [altair]\n",
      "   -------------------- ------------------- 1/2 [altair]\n",
      "   ---------------------------------------- 2/2 [altair]\n",
      "\n",
      "Successfully installed altair-5.5.0 narwhals-2.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install altair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b9745f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting visualization script for Slide 1 (v2)...\n",
      "All 3 data files loaded successfully.\n",
      "Data merge complete. Using 163 data points from 2021.\n",
      "Success: Chart 1 (Boxplot) saved to slide1_boxplot_income_vs_suicide_v2.json\n",
      "Success: Chart 2 (Scatter with Regression) saved to slide1_scatter_hdi_vs_suicide_v2.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# --- 1. Define File Names ---\n",
    "file_hdi = 'human-development-index-(hdi)-by-country-2025.csv'\n",
    "file_suicide = 'suicide-rate-by-country-2025.csv'\n",
    "file_metadata = 'WDICountry.csv'\n",
    "\n",
    "print(\"Starting visualization script for Slide 1 (v2)...\")\n",
    "\n",
    "# --- 2. Load Data ---\n",
    "try:\n",
    "    df_hdi_raw = pd.read_csv(file_hdi)\n",
    "    df_suicide_raw = pd.read_csv(file_suicide)\n",
    "    df_meta = pd.read_csv(file_metadata)\n",
    "    print(\"All 3 data files loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading files: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Process & Merge Data (Same as before) ---\n",
    "# Process HDI\n",
    "hdi_cols_to_melt = ['HumanDevelopmentIndex_2019', 'HumanDevelopmentIndex_2020', 'HumanDevelopmentIndex_2021']\n",
    "hdi_cols_exist = [col for col in hdi_cols_to_melt if col in df_hdi_raw.columns]\n",
    "df_hdi_melted = df_hdi_raw.melt(id_vars=['country'], value_vars=hdi_cols_exist, var_name='HDI_Indicator', value_name='HDI')\n",
    "df_hdi_melted['Year'] = df_hdi_melted['HDI_Indicator'].str.extract(r'(\\d{4})').astype(int)\n",
    "df_hdi_processed = df_hdi_melted[['country', 'Year', 'HDI']]\n",
    "\n",
    "# Process Suicide\n",
    "suicide_cols_to_melt = ['SuicideRateCountries_2019', 'SuicideRateCountries_2020', 'SuicideRateCountries_2021']\n",
    "suicide_cols_exist = [col for col in suicide_cols_to_melt if col in df_suicide_raw.columns]\n",
    "df_suicide_melted = df_suicide_raw.melt(id_vars=['country'], value_vars=suicide_cols_exist, var_name='Suicide_Indicator', value_name='Suicide Rate')\n",
    "df_suicide_melted['Year'] = df_suicide_melted['Suicide_Indicator'].str.extract(r'(\\d{4})').astype(int)\n",
    "df_suicide_processed = df_suicide_melted[['country', 'Year', 'Suicide Rate']]\n",
    "\n",
    "# Process Metadata\n",
    "df_meta_processed = df_meta[['Table Name', 'Region', 'Income Group']].copy()\n",
    "df_meta_processed = df_meta_processed.dropna(subset=['Region', 'Income Group'])\n",
    "df_meta_processed = df_meta_processed.rename(columns={'Table Name': 'country'})\n",
    "\n",
    "# Merge\n",
    "df_merged = pd.merge(df_hdi_processed, df_suicide_processed, on=['country', 'Year'], how='inner')\n",
    "df_final = pd.merge(df_merged, df_meta_processed, on='country', how='inner')\n",
    "\n",
    "# Clean and filter for 2021\n",
    "df_final['HDI'] = pd.to_numeric(df_final['HDI'], errors='coerce')\n",
    "df_final['Suicide Rate'] = pd.to_numeric(df_final['Suicide Rate'], errors='coerce')\n",
    "df_final = df_final.dropna(subset=['HDI', 'Suicide Rate', 'Region', 'Income Group'])\n",
    "df_2021 = df_final[df_final['Year'] == 2021].copy()\n",
    "\n",
    "if df_2021.empty:\n",
    "    print(\"Error: No data for 2021.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(f\"Data merge complete. Using {len(df_2021)} data points from 2021.\")\n",
    "\n",
    "# --- 4. Create Plot 1: Boxplot (Income Group vs Suicide) + Jitter Points (Unchanged) ---\n",
    "try:\n",
    "    income_order = ['Low income', 'Lower middle income', 'Upper middle income', 'High income']\n",
    "    \n",
    "    base_plot1 = alt.Chart(df_2021).encode(\n",
    "        x=alt.X('Income Group', sort=income_order, title='Income Group'),\n",
    "        y=alt.Y('Suicide Rate', title='Suicide Rate (per 100k)')\n",
    "    )\n",
    "    boxplot_layer = base_plot1.mark_boxplot(size=50, opacity=0.4, outliers=True)\n",
    "    points_layer = base_plot1.mark_point(filled=True, size=60, opacity=0.7).encode(\n",
    "        color=alt.Color('Region', title='Continent'),\n",
    "        tooltip=['country', 'Region', 'Income Group', 'Suicide Rate']\n",
    "    )\n",
    "    chart1 = (boxplot_layer + points_layer).properties(\n",
    "        title='Suicide Rate by Income Group and Continent (2021)',\n",
    "        width=600,\n",
    "        height=400\n",
    "    ).interactive()\n",
    "\n",
    "    chart1_file = 'slide1_boxplot_income_vs_suicide_v2.json'\n",
    "    chart1.save(chart1_file)\n",
    "    print(f\"Success: Chart 1 (Boxplot) saved to {chart1_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Chart 1 (Boxplot): {e}\")\n",
    "\n",
    "# --- 5. Create Plot 2: Scatter (HDI vs Suicide) + Threshold Line + Regression Line (MODIFIED) ---\n",
    "try:\n",
    "    average_suicide_rate = df_2021['Suicide Rate'].mean()\n",
    "    \n",
    "    # Base chart for scatter\n",
    "    base_plot2 = alt.Chart(df_2021).encode(\n",
    "        x=alt.X('HDI', title='Human Development Index (HDI)', scale=alt.Scale(zero=False)),\n",
    "        y=alt.Y('Suicide Rate', title='Suicide Rate (per 100k)')\n",
    "    )\n",
    "    \n",
    "    # Layer 1: Scatter plot points\n",
    "    scatter_layer = base_plot2.mark_circle(size=80, opacity=0.8).encode(\n",
    "        color=alt.Color('Region', title='Continent'),\n",
    "        tooltip=['country', 'Region', 'HDI', 'Suicide Rate']\n",
    "    )\n",
    "    \n",
    "    # Layer 2: Horizontal Threshold Line (Red Dashed)\n",
    "    threshold_line = alt.Chart(pd.DataFrame({'y': [average_suicide_rate]})).mark_rule(\n",
    "        color='red',\n",
    "        strokeDash=[5,5], # Dashed line\n",
    "        size=2\n",
    "    ).encode(y='y')\n",
    "    \n",
    "    # Text label for the threshold line\n",
    "    threshold_text = alt.Chart(pd.DataFrame({\n",
    "        'y': [average_suicide_rate], \n",
    "        'label': [f'Global Average: {average_suicide_rate:.2f}']\n",
    "    })\n",
    "    ).mark_text(\n",
    "        align='left',\n",
    "        baseline='bottom',\n",
    "        color='red',\n",
    "        dx=5  # Horizontal offset\n",
    "    ).encode(\n",
    "        y='y',\n",
    "        text='label'\n",
    "    )\n",
    "\n",
    "    # Layer 3: Linear Regression Line (Blue Dashed) - INI YANG BARU\n",
    "    regression_line = base_plot2.transform_regression(\n",
    "        'HDI', 'Suicide Rate', method='linear'\n",
    "    ).mark_line(\n",
    "        color='blue',\n",
    "        strokeDash=[5,5], # Dashed line\n",
    "        size=2\n",
    "    )\n",
    "\n",
    "    # Combine all layers\n",
    "    chart2 = (scatter_layer + threshold_line + threshold_text + regression_line).properties(\n",
    "        title='HDI vs. Suicide Rate by Continent (2021)',\n",
    "        width=700,\n",
    "        height=450\n",
    "    ).interactive()\n",
    "\n",
    "    chart2_file = 'slide1_scatter_hdi_vs_suicide_v2.json'\n",
    "    chart2.save(chart2_file)\n",
    "    print(f\"Success: Chart 2 (Scatter with Regression) saved to {chart2_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Chart 2 (Scatter): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e58e33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting altair_saver\n",
      "  Downloading altair_saver-0.5.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting vega_datasets\n",
      "  Downloading vega_datasets-0.9.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.38.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: altair in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair_saver) (5.5.0)\n",
      "Collecting altair-data-server>=0.4.0 (from altair_saver)\n",
      "  Downloading altair_data_server-0.4.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting altair-viewer (from altair_saver)\n",
      "  Downloading altair_viewer-0.4.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: pandas in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from vega_datasets) (2.3.3)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Collecting trio<1.0,>=0.31.0 (from selenium)\n",
      "  Downloading trio-0.31.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from selenium) (2025.10.5)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from selenium) (1.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
      "Collecting sortedcontainers (from trio<1.0,>=0.31.0->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (3.10)\n",
      "Collecting outcome (from trio<1.0,>=0.31.0->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.0.0)\n",
      "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3.0,>=2.5.0->selenium)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting portpicker (from altair-data-server>=0.4.0->altair_saver)\n",
      "  Downloading portpicker-1.6.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tornado in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair-data-server>=0.4.0->altair_saver) (6.5.2)\n",
      "Requirement already satisfied: pycparser in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.31.0->selenium) (2.23)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Requirement already satisfied: jinja2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_saver) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_saver) (4.25.1)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_saver) (2.9.0)\n",
      "Requirement already satisfied: packaging in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_saver) (25.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_saver) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_saver) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_saver) (0.28.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jinja2->altair->altair_saver) (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas->vega_datasets) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas->vega_datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas->vega_datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas->vega_datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->vega_datasets) (1.17.0)\n",
      "Requirement already satisfied: psutil in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from portpicker->altair-data-server>=0.4.0->altair_saver) (7.1.0)\n",
      "Downloading altair_saver-0.5.0-py3-none-any.whl (89 kB)\n",
      "Downloading vega_datasets-0.9.0-py3-none-any.whl (210 kB)\n",
      "Downloading selenium-4.38.0-py3-none-any.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.8/9.7 MB 8.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.2/9.7 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.3/9.7 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.4/9.7 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 9.9 MB/s  0:00:00\n",
      "Downloading trio-0.31.0-py3-none-any.whl (512 kB)\n",
      "Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading altair_data_server-0.4.1-py3-none-any.whl (12 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading altair_viewer-0.4.0-py3-none-any.whl (844 kB)\n",
      "   ---------------------------------------- 0.0/844.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 844.5/844.5 kB 9.4 MB/s  0:00:00\n",
      "Downloading portpicker-1.6.0-py3-none-any.whl (16 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, wsproto, pysocks, portpicker, outcome, trio, vega_datasets, trio-websocket, selenium, altair-data-server, altair-viewer, altair_saver\n",
      "\n",
      "   ------------- --------------------------  4/12 [outcome]\n",
      "   ---------------- -----------------------  5/12 [trio]\n",
      "   ---------------- -----------------------  5/12 [trio]\n",
      "   ---------------- -----------------------  5/12 [trio]\n",
      "   ---------------- -----------------------  5/12 [trio]\n",
      "   ---------------- -----------------------  5/12 [trio]\n",
      "   ----------------------- ----------------  7/12 [trio-websocket]\n",
      "   -------------------------- -------------  8/12 [selenium]\n",
      "   -------------------------- -------------  8/12 [selenium]\n",
      "   -------------------------- -------------  8/12 [selenium]\n",
      "   -------------------------- -------------  8/12 [selenium]\n",
      "   -------------------------- -------------  8/12 [selenium]\n",
      "   -------------------------- -------------  8/12 [selenium]\n",
      "   -------------------------- -------------  8/12 [selenium]\n",
      "   -------------------------- -------------  8/12 [selenium]\n",
      "   -------------------------- -------------  8/12 [selenium]\n",
      "   -------------------------- -------------  8/12 [selenium]\n",
      "   -------------------------- -------------  8/12 [selenium]\n",
      "   -------------------------- -------------  8/12 [selenium]\n",
      "   ------------------------------ ---------  9/12 [altair-data-server]\n",
      "   ------------------------------------ --- 11/12 [altair_saver]\n",
      "   ---------------------------------------- 12/12 [altair_saver]\n",
      "\n",
      "Successfully installed altair-data-server-0.4.1 altair-viewer-0.4.0 altair_saver-0.5.0 outcome-1.3.0.post0 portpicker-1.6.0 pysocks-1.7.1 selenium-4.38.0 sortedcontainers-2.4.0 trio-0.31.0 trio-websocket-0.12.2 vega_datasets-0.9.0 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install altair_saver vega_datasets selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab8ea77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting altair==4.2.2\n",
      "  Downloading altair-4.2.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: altair_saver==0.5.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (0.5.0)\n",
      "Collecting entrypoints (from altair==4.2.2)\n",
      "  Using cached entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair==4.2.2) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair==4.2.2) (4.25.1)\n",
      "Requirement already satisfied: numpy in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair==4.2.2) (2.2.6)\n",
      "Requirement already satisfied: pandas>=0.18 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair==4.2.2) (2.3.3)\n",
      "Collecting toolz (from altair==4.2.2)\n",
      "  Downloading toolz-1.1.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: altair-data-server>=0.4.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair_saver==0.5.0) (0.4.1)\n",
      "Requirement already satisfied: altair-viewer in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair_saver==0.5.0) (0.4.0)\n",
      "Requirement already satisfied: selenium in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair_saver==0.5.0) (4.38.0)\n",
      "Requirement already satisfied: portpicker in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair-data-server>=0.4.0->altair_saver==0.5.0) (1.6.0)\n",
      "Requirement already satisfied: tornado in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair-data-server>=0.4.0->altair_saver==0.5.0) (6.5.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair==4.2.2) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair==4.2.2) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair==4.2.2) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair==4.2.2) (0.28.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas>=0.18->altair==4.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas>=0.18->altair==4.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas>=0.18->altair==4.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.18->altair==4.2.2) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from referencing>=0.28.4->jsonschema>=3.0->altair==4.2.2) (4.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jinja2->altair==4.2.2) (3.0.3)\n",
      "Requirement already satisfied: psutil in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from portpicker->altair-data-server>=0.4.0->altair_saver==0.5.0) (7.1.0)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium->altair_saver==0.5.0) (2.5.0)\n",
      "Requirement already satisfied: trio<1.0,>=0.31.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from selenium->altair_saver==0.5.0) (0.31.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from selenium->altair_saver==0.5.0) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from selenium->altair_saver==0.5.0) (2025.10.5)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from selenium->altair_saver==0.5.0) (1.9.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium->altair_saver==0.5.0) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium->altair_saver==0.5.0) (3.10)\n",
      "Requirement already satisfied: outcome in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium->altair_saver==0.5.0) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium->altair_saver==0.5.0) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium->altair_saver==0.5.0) (2.0.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio-websocket<1.0,>=0.12.2->selenium->altair_saver==0.5.0) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium->altair_saver==0.5.0) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.31.0->selenium->altair_saver==0.5.0) (2.23)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium->altair_saver==0.5.0) (0.16.0)\n",
      "Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "   ---------------------------------------- 0.0/813.6 kB ? eta -:--:--\n",
      "   ------------------------------------- - 786.4/813.6 kB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 813.6/813.6 kB 2.7 MB/s  0:00:00\n",
      "Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading toolz-1.1.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: toolz, entrypoints, altair\n",
      "\n",
      "   ---------------------------------------- 0/3 [toolz]\n",
      "  Attempting uninstall: altair\n",
      "   ---------------------------------------- 0/3 [toolz]\n",
      "    Found existing installation: altair 5.5.0\n",
      "   ---------------------------------------- 0/3 [toolz]\n",
      "    Uninstalling altair-5.5.0:\n",
      "   ---------------------------------------- 0/3 [toolz]\n",
      "      Successfully uninstalled altair-5.5.0\n",
      "   ---------------------------------------- 0/3 [toolz]\n",
      "   -------------------------- ------------- 2/3 [altair]\n",
      "   -------------------------- ------------- 2/3 [altair]\n",
      "   -------------------------- ------------- 2/3 [altair]\n",
      "   -------------------------- ------------- 2/3 [altair]\n",
      "   -------------------------- ------------- 2/3 [altair]\n",
      "   -------------------------- ------------- 2/3 [altair]\n",
      "   -------------------------- ------------- 2/3 [altair]\n",
      "   -------------------------- ------------- 2/3 [altair]\n",
      "   ---------------------------------------- 3/3 [altair]\n",
      "\n",
      "Successfully installed altair-4.2.2 entrypoints-0.4 toolz-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install altair==4.2.2 altair_saver==0.5.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7ffc88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: altair_viewer in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: altair in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair_viewer) (4.2.2)\n",
      "Requirement already satisfied: altair-data-server>=0.4.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair_viewer) (0.4.1)\n",
      "Requirement already satisfied: portpicker in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair-data-server>=0.4.0->altair_viewer) (1.6.0)\n",
      "Requirement already satisfied: tornado in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair-data-server>=0.4.0->altair_viewer) (6.5.2)\n",
      "Requirement already satisfied: entrypoints in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (4.25.1)\n",
      "Requirement already satisfied: numpy in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (2.2.6)\n",
      "Requirement already satisfied: pandas>=0.18 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (2.3.3)\n",
      "Requirement already satisfied: toolz in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (1.1.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_viewer) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_viewer) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_viewer) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_viewer) (0.28.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas>=0.18->altair->altair_viewer) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas>=0.18->altair->altair_viewer) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas>=0.18->altair->altair_viewer) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.18->altair->altair_viewer) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from referencing>=0.28.4->jsonschema>=3.0->altair->altair_viewer) (4.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jinja2->altair->altair_viewer) (3.0.3)\n",
      "Requirement already satisfied: psutil in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from portpicker->altair-data-server>=0.4.0->altair_viewer) (7.1.0)\n",
      "Requirement already satisfied: altair_viewer in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: altair in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair_viewer) (4.2.2)\n",
      "Requirement already satisfied: altair-data-server>=0.4.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair_viewer) (0.4.1)\n",
      "Requirement already satisfied: portpicker in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair-data-server>=0.4.0->altair_viewer) (1.6.0)\n",
      "Requirement already satisfied: tornado in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair-data-server>=0.4.0->altair_viewer) (6.5.2)\n",
      "Requirement already satisfied: entrypoints in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (4.25.1)\n",
      "Requirement already satisfied: numpy in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (2.2.6)\n",
      "Requirement already satisfied: pandas>=0.18 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (2.3.3)\n",
      "Requirement already satisfied: toolz in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (1.1.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_viewer) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_viewer) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_viewer) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_viewer) (0.28.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas>=0.18->altair->altair_viewer) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas>=0.18->altair->altair_viewer) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas>=0.18->altair->altair_viewer) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.18->altair->altair_viewer) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from referencing>=0.28.4->jsonschema>=3.0->altair->altair_viewer) (4.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jinja2->altair->altair_viewer) (3.0.3)\n",
      "Requirement already satisfied: psutil in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from portpicker->altair-data-server>=0.4.0->altair_viewer) (7.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U altair_viewer\n",
    "!pip install -U altair_viewer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e24b3520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting visualization script for Slide 1 (v4 - PNG attempt)...\n",
      "All 3 data files loaded successfully.\n",
      "Processing and merging data...\n",
      "Data merge complete. Using 163 data points from 2021.\n",
      "Success: Chart 1 (Boxplot) saved to slide1_boxplot_income_vs_suicide.json for display.\n",
      "Error saving Chart 1 as PNG: No matches for version='5.20.1' among ['4.0.2', '4.8.1', '4.17.0'].\n",
      "Often this can be fixed by updating altair_viewer:\n",
      "    pip install -U altair_viewer\n",
      "Success: Chart 2 (Scatter) saved to slide1_scatter_hdi_vs_suicide.json for display.\n",
      "Error saving Chart 2 as PNG: No matches for version='5.20.1' among ['4.0.2', '4.8.1', '4.17.0'].\n",
      "Often this can be fixed by updating altair_viewer:\n",
      "    pip install -U altair_viewer\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import altair_saver\n",
    "\n",
    "\n",
    "# --- 1. Define File Names (FIXED) ---\n",
    "# Nama file diperbaiki, disesuaikan dengan yang kamu upload\n",
    "file_hdi = 'human-development-index-(hdi)-by-country-2025.csv'\n",
    "file_suicide = 'suicide-rate-by-country-2025.csv'\n",
    "file_metadata = 'WDICountry.csv'\n",
    "\n",
    "print(\"Starting visualization script for Slide 1 (v4 - PNG attempt)...\")\n",
    "\n",
    "# --- 2. Load Data ---\n",
    "try:\n",
    "    df_hdi_raw = pd.read_csv(file_hdi)\n",
    "    df_suicide_raw = pd.read_csv(file_suicide)\n",
    "    df_meta = pd.read_csv(file_metadata)\n",
    "    print(\"All 3 data files loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading files: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Process & Merge Data ---\n",
    "print(\"Processing and merging data...\")\n",
    "# (Kode proses dan merge sama persis seperti sebelumnya)\n",
    "hdi_cols_to_melt = ['HumanDevelopmentIndex_2019', 'HumanDevelopmentIndex_2020', 'HumanDevelopmentIndex_2021']\n",
    "hdi_cols_exist = [col for col in hdi_cols_to_melt if col in df_hdi_raw.columns]\n",
    "df_hdi_melted = df_hdi_raw.melt(id_vars=['country'], value_vars=hdi_cols_exist, var_name='HDI_Indicator', value_name='HDI')\n",
    "df_hdi_melted['Year'] = df_hdi_melted['HDI_Indicator'].str.extract(r'(\\d{4})').astype(int)\n",
    "df_hdi_processed = df_hdi_melted[['country', 'Year', 'HDI']]\n",
    "\n",
    "suicide_cols_to_melt = ['SuicideRateCountries_2019', 'SuicideRateCountries_2020', 'SuicideRateCountries_2021']\n",
    "suicide_cols_exist = [col for col in suicide_cols_to_melt if col in df_suicide_raw.columns]\n",
    "df_suicide_melted = df_suicide_raw.melt(id_vars=['country'], value_vars=suicide_cols_exist, var_name='Suicide_Indicator', value_name='Suicide Rate')\n",
    "df_suicide_melted['Year'] = df_suicide_melted['Suicide_Indicator'].str.extract(r'(\\d{4})').astype(int)\n",
    "df_suicide_processed = df_suicide_melted[['country', 'Year', 'Suicide Rate']]\n",
    "\n",
    "df_meta_processed = df_meta[['Table Name', 'Region', 'Income Group']].copy()\n",
    "df_meta_processed = df_meta_processed.dropna(subset=['Region', 'Income Group'])\n",
    "df_meta_processed = df_meta_processed.rename(columns={'Table Name': 'country'})\n",
    "\n",
    "df_merged = pd.merge(df_hdi_processed, df_suicide_processed, on=['country', 'Year'], how='inner')\n",
    "df_final = pd.merge(df_merged, df_meta_processed, on='country', how='inner')\n",
    "\n",
    "df_final['HDI'] = pd.to_numeric(df_final['HDI'], errors='coerce')\n",
    "df_final['Suicide Rate'] = pd.to_numeric(df_final['Suicide Rate'], errors='coerce')\n",
    "df_final = df_final.dropna(subset=['HDI', 'Suicide Rate', 'Region', 'Income Group'])\n",
    "df_2021 = df_final[df_final['Year'] == 2021].copy()\n",
    "\n",
    "if df_2021.empty:\n",
    "    print(\"Error: No data for 2021.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(f\"Data merge complete. Using {len(df_2021)} data points from 2021.\")\n",
    "\n",
    "# --- 4. Create Plot 1: Boxplot (Income Group vs Suicide) ---\n",
    "try:\n",
    "    income_order = ['Low income', 'Lower middle income', 'Upper middle income', 'High income']\n",
    "    \n",
    "    base_plot1 = alt.Chart(df_2021).encode(\n",
    "        x=alt.X('Income Group', sort=income_order, title='Income Group'),\n",
    "        y=alt.Y('Suicide Rate', title='Suicide Rate (per 100k)')\n",
    "    )\n",
    "    boxplot_layer = base_plot1.mark_boxplot(size=50, opacity=0.4, outliers=True)\n",
    "    points_layer = base_plot1.mark_point(filled=True, size=60, opacity=0.7).encode(\n",
    "        color=alt.Color('Region', title='Continent'),\n",
    "        tooltip=['country', 'Region', 'Income Group', 'Suicide Rate']\n",
    "    )\n",
    "    chart1 = (boxplot_layer + points_layer).properties(\n",
    "        title='Suicide Rate by Income Group and Continent (2021)',\n",
    "        width=600,\n",
    "        height=400\n",
    "    ).interactive()\n",
    "\n",
    "    # Save as JSON (this is what gets displayed)\n",
    "    chart1_file_json = 'slide1_boxplot_income_vs_suicide.json'\n",
    "    chart1.save(chart1_file_json)\n",
    "    print(f\"Success: Chart 1 (Boxplot) saved to {chart1_file_json} for display.\")\n",
    "    \n",
    "    # Attempt to save as PNG\n",
    "    try:\n",
    "        from altair_saver import save\n",
    "        chart1_file_png = 'slide1_boxplot_income_vs_suicide.png'\n",
    "        save(chart1, chart1_file_png)\n",
    "        print(f\"Success: Chart 1 (Boxplot) also saved to {chart1_file_png}.\")\n",
    "    except ImportError:\n",
    "        print(\"Info: 'altair_saver' library not found. Cannot save as PNG.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving Chart 1 as PNG: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Chart 1 (Boxplot): {e}\")\n",
    "\n",
    "# --- 5. Create Plot 2: Scatter (HDI vs Suicide) + Threshold Line + Regression Line ---\n",
    "try:\n",
    "    average_suicide_rate = df_2021['Suicide Rate'].mean()\n",
    "    \n",
    "    base_plot2 = alt.Chart(df_2021).encode(\n",
    "        x=alt.X('HDI', title='Human Development Index (HDI)', scale=alt.Scale(zero=False)),\n",
    "        y=alt.Y('Suicide Rate', title='Suicide Rate (per 100k)')\n",
    "    )\n",
    "    \n",
    "    scatter_layer = base_plot2.mark_circle(size=80, opacity=0.8).encode(\n",
    "        color=alt.Color('Region', title='Continent'),\n",
    "        tooltip=['country', 'Region', 'HDI', 'Suicide Rate']\n",
    "    )\n",
    "    \n",
    "    threshold_line = alt.Chart(pd.DataFrame({'y': [average_suicide_rate]})).mark_rule(\n",
    "        color='red', strokeDash=[5,5], size=2\n",
    "    ).encode(y='y')\n",
    "    \n",
    "    threshold_text = alt.Chart(pd.DataFrame({\n",
    "        'y': [average_suicide_rate], \n",
    "        'label': [f'Global Average: {average_suicide_rate:.2f}']\n",
    "    })).mark_text(\n",
    "        align='left', baseline='bottom', color='red', dx=5\n",
    "    ).encode(y='y', text='label')\n",
    "\n",
    "    regression_line = base_plot2.transform_regression(\n",
    "        'HDI', 'Suicide Rate', method='linear'\n",
    "    ).mark_line(\n",
    "        color='blue', strokeDash=[5,5], size=2\n",
    "    )\n",
    "\n",
    "    chart2 = (scatter_layer + threshold_line + threshold_text + regression_line).properties(\n",
    "        title='HDI vs. Suicide Rate by Continent (2021)',\n",
    "        width=700,\n",
    "        height=450\n",
    "    ).interactive()\n",
    "\n",
    "    # Save as JSON (this is what gets displayed)\n",
    "    chart2_file_json = 'slide1_scatter_hdi_vs_suicide.json'\n",
    "    chart2.save(chart2_file_json)\n",
    "    print(f\"Success: Chart 2 (Scatter) saved to {chart2_file_json} for display.\")\n",
    "\n",
    "    # Attempt to save as PNG\n",
    "    try:\n",
    "        from altair_saver import save\n",
    "        chart2_file_png = 'slide1_scatter_hdi_vs_suicide.png'\n",
    "        save(chart2, chart2_file_png)\n",
    "        print(f\"Success: Chart 2 (Scatter) also saved to {chart2_file_png}.\")\n",
    "    except ImportError:\n",
    "        print(\"Info: 'altair_saver' library not found. Cannot save as PNG.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving Chart 2 as PNG: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Chart 2 (Scatter): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9714f71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: altair_saver in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: altair in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair_saver) (4.2.2)\n",
      "Requirement already satisfied: altair-data-server>=0.4.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair_saver) (0.4.1)\n",
      "Requirement already satisfied: altair-viewer in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair_saver) (0.4.0)\n",
      "Requirement already satisfied: selenium in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair_saver) (4.38.0)\n",
      "Requirement already satisfied: portpicker in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair-data-server>=0.4.0->altair_saver) (1.6.0)\n",
      "Requirement already satisfied: tornado in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair-data-server>=0.4.0->altair_saver) (6.5.2)\n",
      "Requirement already satisfied: entrypoints in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_saver) (0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_saver) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_saver) (4.25.1)\n",
      "Requirement already satisfied: numpy in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_saver) (2.2.6)\n",
      "Requirement already satisfied: pandas>=0.18 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_saver) (2.3.3)\n",
      "Requirement already satisfied: toolz in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_saver) (1.1.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_saver) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_saver) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_saver) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_saver) (0.28.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas>=0.18->altair->altair_saver) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas>=0.18->altair->altair_saver) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas>=0.18->altair->altair_saver) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.18->altair->altair_saver) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from referencing>=0.28.4->jsonschema>=3.0->altair->altair_saver) (4.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jinja2->altair->altair_saver) (3.0.3)\n",
      "Requirement already satisfied: psutil in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from portpicker->altair-data-server>=0.4.0->altair_saver) (7.1.0)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium->altair_saver) (2.5.0)\n",
      "Requirement already satisfied: trio<1.0,>=0.31.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from selenium->altair_saver) (0.31.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from selenium->altair_saver) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from selenium->altair_saver) (2025.10.5)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from selenium->altair_saver) (1.9.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium->altair_saver) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium->altair_saver) (3.10)\n",
      "Requirement already satisfied: outcome in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium->altair_saver) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium->altair_saver) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium->altair_saver) (2.0.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio-websocket<1.0,>=0.12.2->selenium->altair_saver) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium->altair_saver) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.31.0->selenium->altair_saver) (2.23)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium->altair_saver) (0.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install altair_saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8419976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (4.38.0)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio<1.0,>=0.31.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from selenium) (0.31.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from selenium) (2025.10.5)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from selenium) (1.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.0.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.31.0->selenium) (2.23)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8b5c33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: altair_viewer in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: altair in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair_viewer) (4.2.2)\n",
      "Requirement already satisfied: altair-data-server>=0.4.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair_viewer) (0.4.1)\n",
      "Requirement already satisfied: portpicker in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair-data-server>=0.4.0->altair_viewer) (1.6.0)\n",
      "Requirement already satisfied: tornado in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair-data-server>=0.4.0->altair_viewer) (6.5.2)\n",
      "Requirement already satisfied: entrypoints in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (4.25.1)\n",
      "Requirement already satisfied: numpy in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (2.2.6)\n",
      "Requirement already satisfied: pandas>=0.18 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (2.3.3)\n",
      "Requirement already satisfied: toolz in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from altair->altair_viewer) (1.1.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_viewer) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_viewer) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_viewer) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jsonschema>=3.0->altair->altair_viewer) (0.28.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas>=0.18->altair->altair_viewer) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas>=0.18->altair->altair_viewer) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas>=0.18->altair->altair_viewer) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.18->altair->altair_viewer) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from referencing>=0.28.4->jsonschema>=3.0->altair->altair_viewer) (4.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from jinja2->altair->altair_viewer) (3.0.3)\n",
      "Requirement already satisfied: psutil in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from portpicker->altair-data-server>=0.4.0->altair_viewer) (7.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U altair_viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb9add19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vl-convert-python\n",
      "  Downloading vl_convert_python-1.8.0-cp37-abi3-win_amd64.whl.metadata (5.2 kB)\n",
      "Downloading vl_convert_python-1.8.0-cp37-abi3-win_amd64.whl (31.3 MB)\n",
      "   ---------------------------------------- 0.0/31.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.3/31.3 MB 7.5 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 3.4/31.3 MB 9.2 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 5.5/31.3 MB 9.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 7.3/31.3 MB 9.3 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 9.4/31.3 MB 9.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 11.3/31.3 MB 9.3 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 13.4/31.3 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 15.2/31.3 MB 9.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 17.0/31.3 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 18.9/31.3 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 20.2/31.3 MB 9.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 22.8/31.3 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 24.6/31.3 MB 9.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 26.5/31.3 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 28.6/31.3 MB 9.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 30.4/31.3 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 31.3/31.3 MB 9.0 MB/s  0:00:03\n",
      "Installing collected packages: vl-convert-python\n",
      "Successfully installed vl-convert-python-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vl-convert-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8c14580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mencoba menyimpan PNG menggunakan 'vl-convert'...\n",
      "Berhasil menyimpan: hdi_vs_suicide_plot.png\n",
      "\n",
      "Terjadi error: Vega-Lite to PNG conversion failed:\n",
      "Error: Duplicate signal name: \"param_9_Income_Group\"\n",
      "    at l (https://cdn.jsdelivr.net/npm/vega-util@2.0.0/+esm:7:324)\n",
      "    at hi.addSignal (https://cdn.jsdelivr.net/npm/vega-parser@7.0.0/+esm:7:45557)\n",
      "    at te (https://cdn.jsdelivr.net/npm/vega-parser@7.0.0/+esm:7:4228)\n",
      "    at https://cdn.jsdelivr.net/npm/vega-parser@7.0.0/+esm:7:38925\n",
      "    at Array.forEach (<anonymous>)\n",
      "    at gi (https://cdn.jsdelivr.net/npm/vega-parser@7.0.0/+esm:7:38913)\n",
      "    at Module.$i (https://cdn.jsdelivr.net/npm/vega-parser@7.0.0/+esm:7:43022)\n",
      "    at vegaToView (ext:<anon>:3:24)\n",
      "    at vegaToSvg (ext:<anon>:33:16)\n",
      "    at vegaLiteToSvg_v6_1 (ext:<anon>:23:12)\n",
      "Pastikan kamu sudah menjalankan 'pip install vl-convert-python'\n"
     ]
    }
   ],
   "source": [
    "import vl_convert as vlc\n",
    "import json\n",
    "\n",
    "print(\"Mencoba menyimpan PNG menggunakan 'vl-convert'...\")\n",
    "\n",
    "try:\n",
    "    # --- 1. Muat file JSON scatter plot ---\n",
    "    with open('slide1_scatter_hdi_vs_suicide.json', 'r') as f:\n",
    "        chart_scatter_json = json.load(f)\n",
    "    \n",
    "    # Convert ke PNG\n",
    "    png_data_scatter = vlc.vegalite_to_png(vl_spec=chart_scatter_json)\n",
    "    \n",
    "    # Simpan file PNG\n",
    "    with open(\"hdi_vs_suicide_plot.png\", \"wb\") as f:\n",
    "        f.write(png_data_scatter)\n",
    "    print(\"Berhasil menyimpan: hdi_vs_suicide_plot.png\")\n",
    "\n",
    "\n",
    "    # --- 2. Muat file JSON boxplot ---\n",
    "    with open('slide1_boxplot_income_vs_suicide.json', 'r') as f:\n",
    "        chart_boxplot_json = json.load(f)\n",
    "\n",
    "    # Convert ke PNG\n",
    "    png_data_boxplot = vlc.vegalite_to_png(vl_spec=chart_boxplot_json)\n",
    "\n",
    "    # Simpan file PNG\n",
    "    with open(\"income_vs_suicide_plot.png\", \"wb\") as f:\n",
    "        f.write(png_data_boxplot)\n",
    "    print(\"Berhasil menyimpan: income_vs_suicide_plot.png\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nTerjadi error: {e}\")\n",
    "    print(\"Pastikan kamu sudah menjalankan 'pip install vl-convert-python'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b2ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09ce51dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mencoba memuat 'slide1_boxplot_income_vs_suicide.json'...\n",
      "File JSON berhasil dimuat.\n",
      "Mengonversi ke PNG...\n",
      "\n",
      "Terjadi error: Vega-Lite to PNG conversion failed:\n",
      "Error: Duplicate signal name: \"param_9_Income_Group\"\n",
      "    at l (https://cdn.jsdelivr.net/npm/vega-util@2.0.0/+esm:7:324)\n",
      "    at hi.addSignal (https://cdn.jsdelivr.net/npm/vega-parser@7.0.0/+esm:7:45557)\n",
      "    at te (https://cdn.jsdelivr.net/npm/vega-parser@7.0.0/+esm:7:4228)\n",
      "    at https://cdn.jsdelivr.net/npm/vega-parser@7.0.0/+esm:7:38925\n",
      "    at Array.forEach (<anonymous>)\n",
      "    at gi (https://cdn.jsdelivr.net/npm/vega-parser@7.0.0/+esm:7:38913)\n",
      "    at Module.$i (https://cdn.jsdelivr.net/npm/vega-parser@7.0.0/+esm:7:43022)\n",
      "    at vegaToView (ext:<anon>:3:24)\n",
      "    at vegaToSvg (ext:<anon>:33:16)\n",
      "    at vegaLiteToSvg_v6_1 (ext:<anon>:23:12)\n",
      "Pastikan kamu sudah menjalankan 'pip install vl-convert-python'\n"
     ]
    }
   ],
   "source": [
    "import vl_convert as vlc\n",
    "import json\n",
    "\n",
    "# Nama file JSON input (yang sudah kita buat)\n",
    "json_file_name = 'slide1_boxplot_income_vs_suicide.json'\n",
    "\n",
    "# Nama file PNG output (yang kamu inginkan)\n",
    "png_file_name = 'income_vs_suicide_plot.png'\n",
    "\n",
    "print(f\"Mencoba memuat '{json_file_name}'...\")\n",
    "\n",
    "try:\n",
    "    # --- 1. Muat file JSON boxplot ---\n",
    "    with open(json_file_name, 'r') as f:\n",
    "        chart_boxplot_json = json.load(f)\n",
    "    print(\"File JSON berhasil dimuat.\")\n",
    "\n",
    "    # --- 2. Convert ke PNG ---\n",
    "    print(\"Mengonversi ke PNG...\")\n",
    "    png_data_boxplot = vlc.vegalite_to_png(vl_spec=chart_boxplot_json)\n",
    "\n",
    "    # --- 3. Simpan file PNG ---\n",
    "    with open(png_file_name, \"wb\") as f:\n",
    "        f.write(png_data_boxplot)\n",
    "    \n",
    "    print(f\"\\n--- BERHASIL ---\")\n",
    "    print(f\"Plot berhasil disimpan sebagai: {png_file_name}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nERROR: File tidak ditemukan: '{json_file_name}'\")\n",
    "    print(\"Pastikan file JSON itu ada di folder yang sama dengan script ini.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nTerjadi error: {e}\")\n",
    "    print(\"Pastikan kamu sudah menjalankan 'pip install vl-convert-python'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaf0a2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Langkah 1: Membuat Ulang JSON (Versi Statis) ---\n",
      "Data berhasil dimuat.\n",
      "Memproses data...\n",
      "Data selesai diproses.\n",
      "\n",
      "--- BERHASIL (Langkah 1) ---\n",
      "File JSON statis baru telah disimpan ke: slide1_boxplot_income_vs_suicide.json\n",
      "Sekarang, jalankan script konversi PNG-mu lagi.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# --- 1. Define File Names ---\n",
    "file_hdi = 'human-development-index-(hdi)-by-country-2025.csv'\n",
    "file_suicide = 'suicide-rate-by-country-2025.csv'\n",
    "file_metadata = 'WDICountry.csv'\n",
    "\n",
    "print(\"--- Langkah 1: Membuat Ulang JSON (Versi Statis) ---\")\n",
    "\n",
    "# --- 2. Load Data ---\n",
    "try:\n",
    "    df_hdi_raw = pd.read_csv(file_hdi)\n",
    "    df_suicide_raw = pd.read_csv(file_suicide)\n",
    "    df_meta = pd.read_csv(file_metadata)\n",
    "    print(\"Data berhasil dimuat.\")\n",
    "except Exception as e:\n",
    "    print(f\"Gagal memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Process & Merge Data ---\n",
    "print(\"Memproses data...\")\n",
    "# (Kode proses data disingkat, sama seperti sebelumnya)\n",
    "hdi_cols_to_melt = ['HumanDevelopmentIndex_2019', 'HumanDevelopmentIndex_2020', 'HumanDevelopmentIndex_2021']\n",
    "hdi_cols_exist = [col for col in hdi_cols_to_melt if col in df_hdi_raw.columns]\n",
    "df_hdi_melted = df_hdi_raw.melt(id_vars=['country'], value_vars=hdi_cols_exist, var_name='HDI_Indicator', value_name='HDI')\n",
    "df_hdi_melted['Year'] = df_hdi_melted['HDI_Indicator'].str.extract(r'(\\d{4})').astype(int)\n",
    "df_hdi_processed = df_hdi_melted[['country', 'Year', 'HDI']]\n",
    "\n",
    "suicide_cols_to_melt = ['SuicideRateCountries_2019', 'SuicideRateCountries_2020', 'SuicideRateCountries_2021']\n",
    "suicide_cols_exist = [col for col in suicide_cols_to_melt if col in df_suicide_raw.columns]\n",
    "df_suicide_melted = df_suicide_raw.melt(id_vars=['country'], value_vars=suicide_cols_exist, var_name='Suicide_Indicator', value_name='Suicide Rate')\n",
    "df_suicide_melted['Year'] = df_suicide_melted['Suicide_Indicator'].str.extract(r'(\\d{4})').astype(int)\n",
    "df_suicide_processed = df_suicide_melted[['country', 'Year', 'Suicide Rate']]\n",
    "\n",
    "df_meta_processed = df_meta[['Table Name', 'Region', 'Income Group']].copy()\n",
    "df_meta_processed = df_meta_processed.dropna(subset=['Region', 'Income Group'])\n",
    "df_meta_processed = df_meta_processed.rename(columns={'Table Name': 'country'})\n",
    "\n",
    "df_merged = pd.merge(df_hdi_processed, df_suicide_processed, on=['country', 'Year'], how='inner')\n",
    "df_final = pd.merge(df_merged, df_meta_processed, on='country', how='inner')\n",
    "\n",
    "df_final['HDI'] = pd.to_numeric(df_final['HDI'], errors='coerce')\n",
    "df_final['Suicide Rate'] = pd.to_numeric(df_final['Suicide Rate'], errors='coerce')\n",
    "df_final = df_final.dropna(subset=['HDI', 'Suicide Rate', 'Region', 'Income Group'])\n",
    "df_2021 = df_final[df_final['Year'] == 2021].copy()\n",
    "print(\"Data selesai diproses.\")\n",
    "\n",
    "# --- 4. Create Plot 1 (Boxplot) - VERSI STATIS ---\n",
    "# (Ini bagian yang diubah)\n",
    "try:\n",
    "    income_order = ['Low income', 'Lower middle income', 'Upper middle income', 'High income']\n",
    "    \n",
    "    base_plot1 = alt.Chart(df_2021).encode(\n",
    "        x=alt.X('Income Group', sort=income_order, title='Income Group'),\n",
    "        y=alt.Y('Suicide Rate', title='Suicide Rate (per 100k)')\n",
    "    )\n",
    "    boxplot_layer = base_plot1.mark_boxplot(size=50, opacity=0.4, outliers=True)\n",
    "    \n",
    "    points_layer = base_plot1.mark_point(filled=True, size=60, opacity=0.7).encode(\n",
    "        color=alt.Color('Region', title='Continent')\n",
    "        # Tooltip dihilangkan untuk menghindari bug\n",
    "    )\n",
    "    \n",
    "    chart1 = (boxplot_layer + points_layer).properties(\n",
    "        title='Suicide Rate by Income Group and Continent (2021)',\n",
    "        width=600,\n",
    "        height=400\n",
    "    ) # .interactive() dihilangkan untuk menghindari bug\n",
    "\n",
    "    # Simpan file JSON (menimpa file lama)\n",
    "    chart1_file = 'slide1_boxplot_income_vs_suicide.json'\n",
    "    chart1.save(chart1_file)\n",
    "    print(f\"\\n--- BERHASIL (Langkah 1) ---\")\n",
    "    print(f\"File JSON statis baru telah disimpan ke: {chart1_file}\")\n",
    "    print(\"Sekarang, jalankan script konversi PNG-mu lagi.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error membuat chart statis: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eff3b2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Langkah 2: Mengonversi JSON ke PNG ---\n",
      "Mencoba memuat 'slide1_boxplot_income_vs_suicide.json'...\n",
      "File JSON berhasil dimuat.\n",
      "Mengonversi ke PNG...\n",
      "\n",
      "--- BERHASIL (Langkah 2) ---\n",
      "Plot berhasil disimpan sebagai: income_vs_suicide_plot.png\n"
     ]
    }
   ],
   "source": [
    "import vl_convert as vlc\n",
    "import json\n",
    "\n",
    "# Nama file JSON input (yang baru saja kamu buat ulang)\n",
    "json_file_name = 'slide1_boxplot_income_vs_suicide.json'\n",
    "\n",
    "# Nama file PNG output\n",
    "png_file_name = 'income_vs_suicide_plot.png'\n",
    "\n",
    "print(f\"\\n--- Langkah 2: Mengonversi JSON ke PNG ---\")\n",
    "print(f\"Mencoba memuat '{json_file_name}'...\")\n",
    "\n",
    "try:\n",
    "    with open(json_file_name, 'r') as f:\n",
    "        chart_boxplot_json = json.load(f)\n",
    "    print(\"File JSON berhasil dimuat.\")\n",
    "\n",
    "    print(\"Mengonversi ke PNG...\")\n",
    "    png_data_boxplot = vlc.vegalite_to_png(vl_spec=chart_boxplot_json)\n",
    "\n",
    "    with open(png_file_name, \"wb\") as f:\n",
    "        f.write(png_data_boxplot)\n",
    "    \n",
    "    print(f\"\\n--- BERHASIL (Langkah 2) ---\")\n",
    "    print(f\"Plot berhasil disimpan sebagai: {png_file_name}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nTerjadi error saat konversi: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "520b0220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script visualisasi (perbaikan xOffset) ---\n",
      "Semua 3 file data berhasil dimuat.\n",
      "Memproses dan menggabungkan data...\n",
      "Data 2021 siap (total 163 negara).\n",
      "Success: Chart 1 (Boxplot Statis) disimpan ke slide1_boxplot_STATIC.json\n",
      "Success: Chart 2 (Scatter Statis) disimpan ke slide1_scatter_STATIC.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# --- 1. Define File Names ---\n",
    "file_hdi = 'human-development-index-(hdi)-by-country-2025.csv'\n",
    "file_suicide = 'suicide-rate-by-country-2025.csv'\n",
    "file_metadata = 'WDICountry.csv'\n",
    "\n",
    "print(\"--- Memulai script visualisasi (perbaikan xOffset) ---\")\n",
    "\n",
    "# --- 2. Load Data ---\n",
    "try:\n",
    "    df_hdi_raw = pd.read_csv(file_hdi)\n",
    "    df_suicide_raw = pd.read_csv(file_suicide)\n",
    "    df_meta = pd.read_csv(file_metadata)\n",
    "    print(\"Semua 3 file data berhasil dimuat.\")\n",
    "except Exception as e:\n",
    "    print(f\"Gagal memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Process & Merge Data ---\n",
    "print(\"Memproses dan menggabungkan data...\")\n",
    "hdi_cols_to_melt = ['HumanDevelopmentIndex_2019', 'HumanDevelopmentIndex_2020', 'HumanDevelopmentIndex_2021']\n",
    "hdi_cols_exist = [col for col in hdi_cols_to_melt if col in df_hdi_raw.columns]\n",
    "df_hdi_melted = df_hdi_raw.melt(id_vars=['country'], value_vars=hdi_cols_exist, var_name='HDI_Indicator', value_name='HDI')\n",
    "df_hdi_melted['Year'] = df_hdi_melted['HDI_Indicator'].str.extract(r'(\\d{4})').astype(int)\n",
    "df_hdi_processed = df_hdi_melted[['country', 'Year', 'HDI']]\n",
    "\n",
    "suicide_cols_to_melt = ['SuicideRateCountries_2019', 'SuicideRateCountries_2020', 'SuicideRateCountries_2021']\n",
    "suicide_cols_exist = [col for col in suicide_cols_to_melt if col in df_suicide_raw.columns]\n",
    "df_suicide_melted = df_suicide_raw.melt(id_vars=['country'], value_vars=suicide_cols_exist, var_name='Suicide_Indicator', value_name='Suicide Rate')\n",
    "df_suicide_melted['Year'] = df_suicide_melted['Suicide_Indicator'].str.extract(r'(\\d{4})').astype(int)\n",
    "df_suicide_processed = df_suicide_melted[['country', 'Year', 'Suicide Rate']]\n",
    "\n",
    "df_meta_processed = df_meta[['Table Name', 'Region', 'Income Group']].copy()\n",
    "df_meta_processed = df_meta_processed.dropna(subset=['Region', 'Income Group'])\n",
    "df_meta_processed = df_meta_processed.rename(columns={'Table Name': 'country'})\n",
    "\n",
    "df_merged = pd.merge(df_hdi_processed, df_suicide_processed, on=['country', 'Year'], how='inner')\n",
    "df_final = pd.merge(df_merged, df_meta_processed, on='country', how='inner')\n",
    "\n",
    "df_final['HDI'] = pd.to_numeric(df_final['HDI'], errors='coerce')\n",
    "df_final['Suicide Rate'] = pd.to_numeric(df_final['Suicide Rate'], errors='coerce')\n",
    "df_final = df_final.dropna(subset=['HDI', 'Suicide Rate', 'Region', 'Income Group'])\n",
    "df_2021 = df_final[df_final['Year'] == 2021].copy()\n",
    "print(f\"Data 2021 siap (total {len(df_2021)} negara).\")\n",
    "\n",
    "\n",
    "# --- 4. Create Plot 1 (Boxplot) - DIPERBAIKI ---\n",
    "try:\n",
    "    income_order = ['Low income', 'Lower middle income', 'Upper middle income', 'High income']\n",
    "    \n",
    "    base_plot1 = alt.Chart(df_2021).encode(\n",
    "        x=alt.X('Income Group', sort=income_order, title='Income Group'),\n",
    "        y=alt.Y('Suicide Rate', title='Suicide Rate (per 100k)')\n",
    "    )\n",
    "    \n",
    "    # Layer 1: Boxplot (di tengah, lebih tipis)\n",
    "    boxplot_layer = base_plot1.mark_boxplot(\n",
    "        size=30,  # Box lebih tipis\n",
    "        opacity=0.6, \n",
    "        outliers=True\n",
    "        # xOffset DIHAPUS karena menyebabkan error\n",
    "    )\n",
    "    \n",
    "    # Layer 2: Points (diperkecil dan digeser ke kanan)\n",
    "    points_layer = base_plot1.mark_point(\n",
    "        filled=True,\n",
    "        size=20,  # Titik diperkecil\n",
    "        opacity=0.7,\n",
    "        xOffset=25 # Geser ke kanan (hanya titiknya)\n",
    "    ).encode(\n",
    "        color=alt.Color('Region', title='Continent')\n",
    "        # Tooltip dan .interactive() sengaja dihilangkan\n",
    "    )\n",
    "    \n",
    "    chart1 = (boxplot_layer + points_layer).properties(\n",
    "        title='Suicide Rate by Income Group and Continent (2021)',\n",
    "        width=600,\n",
    "        height=400\n",
    "    )\n",
    "\n",
    "    chart1_file = 'slide1_boxplot_STATIC.json'\n",
    "    chart1.save(chart1_file)\n",
    "    print(f\"Success: Chart 1 (Boxplot Statis) disimpan ke {chart1_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error membuat Chart 1 (Boxplot): {e}\")\n",
    "\n",
    "# --- 5. Create Plot 2 (Scatter) - (Tidak Berubah) ---\n",
    "try:\n",
    "    base_plot2 = alt.Chart(df_2021).encode(\n",
    "        x=alt.X('HDI', title='Human Development Index (HDI)', scale=alt.Scale(zero=False)),\n",
    "        y=alt.Y('Suicide Rate', title='Suicide Rate (per 100k)')\n",
    "    )\n",
    "    \n",
    "    scatter_layer = base_plot2.mark_circle(size=80, opacity=0.8).encode(\n",
    "        color=alt.Color('Region', title='Continent')\n",
    "    )\n",
    "    \n",
    "    regression_line = base_plot2.transform_regression(\n",
    "        'HDI', 'Suicide Rate', method='linear'\n",
    "    ).mark_line(\n",
    "        color='black', \n",
    "        size=2\n",
    "    )\n",
    "\n",
    "    chart2 = (scatter_layer + regression_line).properties(\n",
    "        title='HDI vs. Suicide Rate by Continent (2021)',\n",
    "        width=700,\n",
    "        height=450\n",
    "    )\n",
    "\n",
    "    chart2_file = 'slide1_scatter_STATIC.json'\n",
    "    chart2.save(chart2_file)\n",
    "    print(f\"Success: Chart 2 (Scatter Statis) disimpan ke {chart2_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error membuat Chart 2 (Scatter): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb87048b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai Konversi JSON Statis ke PNG ---\n",
      "\n",
      "Memproses: 'slide1_boxplot_STATIC.json'\n",
      "'slide1_boxplot_STATIC.json' berhasil dimuat.\n",
      "Mengonversi ke PNG...\n",
      "--- BERHASIL disimpan sebagai: income_vs_suicide_plot.png ---\n",
      "\n",
      "Memproses: 'slide1_scatter_STATIC.json'\n",
      "'slide1_scatter_STATIC.json' berhasil dimuat.\n",
      "Mengonversi ke PNG...\n",
      "--- BERHASIL disimpan sebagai: hdi_vs_suicide_plot.png ---\n",
      "\n",
      "--- Konversi Selesai ---\n"
     ]
    }
   ],
   "source": [
    "import vl_convert as vlc\n",
    "import json\n",
    "\n",
    "print(\"--- Memulai Konversi JSON Statis ke PNG ---\")\n",
    "\n",
    "# --- Daftar Plot untuk Dikonversi ---\n",
    "plots_to_convert = [\n",
    "    {\n",
    "        \"json_in\": \"slide1_boxplot_STATIC.json\",\n",
    "        \"png_out\": \"income_vs_suicide_plot.png\"\n",
    "    },\n",
    "    {\n",
    "        \"json_in\": \"slide1_scatter_STATIC.json\",\n",
    "        \"png_out\": \"hdi_vs_suicide_plot.png\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- Loop Konversi ---\n",
    "for plot in plots_to_convert:\n",
    "    json_file = plot[\"json_in\"]\n",
    "    png_file = plot[\"png_out\"]\n",
    "    \n",
    "    print(f\"\\nMemproses: '{json_file}'\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Muat file JSON statis\n",
    "        with open(json_file, 'r') as f:\n",
    "            chart_json = json.load(f)\n",
    "        print(f\"'{json_file}' berhasil dimuat.\")\n",
    "\n",
    "        # 2. Konversi ke PNG\n",
    "        print(f\"Mengonversi ke PNG...\")\n",
    "        png_data = vlc.vegalite_to_png(vl_spec=chart_json)\n",
    "\n",
    "        # 3. Simpan file PNG\n",
    "        with open(png_file, \"wb\") as f:\n",
    "            f.write(png_data)\n",
    "        \n",
    "        print(f\"--- BERHASIL disimpan sebagai: {png_file} ---\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: File tidak ditemukan: '{json_file}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR saat memproses '{json_file}': {e}\")\n",
    "        print(\"Pastikan kamu sudah menjalankan 'pip install vl-convert-python'\")\n",
    "\n",
    "print(\"\\n--- Konversi Selesai ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6117c8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script Perbaikan Boxplot (Label Horizontal) ---\n",
      "Semua 3 file data berhasil dimuat.\n",
      "Memproses dan menggabungkan data...\n",
      "Data 2021 siap (total 163 negara).\n",
      "Success: Boxplot (Label Horizontal) disimpan ke slide1_boxplot_STATIC_horizontal.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\Lib\\site-packages\\altair\\utils\\core.py:384: FutureWarning:\n",
      "\n",
      "the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "\n",
      "c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\Lib\\site-packages\\altair\\utils\\core.py:384: FutureWarning:\n",
      "\n",
      "the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "\n",
      "c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\Lib\\site-packages\\altair\\utils\\core.py:384: FutureWarning:\n",
      "\n",
      "the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# --- 1. Define File Names ---\n",
    "file_hdi = 'human-development-index-(hdi)-by-country-2025.csv'\n",
    "file_suicide = 'suicide-rate-by-country-2025.csv'\n",
    "file_metadata = 'WDICountry.csv'\n",
    "\n",
    "print(\"--- Memulai script Perbaikan Boxplot (Label Horizontal) ---\")\n",
    "\n",
    "# --- 2. Load Data ---\n",
    "try:\n",
    "    df_hdi_raw = pd.read_csv(file_hdi)\n",
    "    df_suicide_raw = pd.read_csv(file_suicide)\n",
    "    df_meta = pd.read_csv(file_metadata)\n",
    "    print(\"Semua 3 file data berhasil dimuat.\")\n",
    "except Exception as e:\n",
    "    print(f\"Gagal memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Process & Merge Data ---\n",
    "# (Kode ini sama seperti sebelumnya, untuk menyiapkan data)\n",
    "print(\"Memproses dan menggabungkan data...\")\n",
    "hdi_cols_to_melt = ['HumanDevelopmentIndex_2019', 'HumanDevelopmentIndex_2020', 'HumanDevelopmentIndex_2021']\n",
    "hdi_cols_exist = [col for col in hdi_cols_to_melt if col in df_hdi_raw.columns]\n",
    "df_hdi_melted = df_hdi_raw.melt(id_vars=['country'], value_vars=hdi_cols_exist, var_name='HDI_Indicator', value_name='HDI')\n",
    "df_hdi_melted['Year'] = df_hdi_melted['HDI_Indicator'].str.extract(r'(\\d{4})').astype(int)\n",
    "df_hdi_processed = df_hdi_melted[['country', 'Year', 'HDI']]\n",
    "\n",
    "suicide_cols_to_melt = ['SuicideRateCountries_2019', 'SuicideRateCountries_2020', 'SuicideRateCountries_2021']\n",
    "suicide_cols_exist = [col for col in suicide_cols_to_melt if col in df_suicide_raw.columns]\n",
    "df_suicide_melted = df_suicide_raw.melt(id_vars=['country'], value_vars=suicide_cols_exist, var_name='Suicide_Indicator', value_name='Suicide Rate')\n",
    "df_suicide_melted['Year'] = df_suicide_melted['Suicide_Indicator'].str.extract(r'(\\d{4})').astype(int)\n",
    "df_suicide_processed = df_suicide_melted[['country', 'Year', 'Suicide Rate']]\n",
    "\n",
    "df_meta_processed = df_meta[['Table Name', 'Region', 'Income Group']].copy()\n",
    "df_meta_processed = df_meta_processed.dropna(subset=['Region', 'Income Group'])\n",
    "df_meta_processed = df_meta_processed.rename(columns={'Table Name': 'country'})\n",
    "\n",
    "df_merged = pd.merge(df_hdi_processed, df_suicide_processed, on=['country', 'Year'], how='inner')\n",
    "df_final = pd.merge(df_merged, df_meta_processed, on='country', how='inner')\n",
    "\n",
    "df_final['HDI'] = pd.to_numeric(df_final['HDI'], errors='coerce')\n",
    "df_final['Suicide Rate'] = pd.to_numeric(df_final['Suicide Rate'], errors='coerce')\n",
    "df_final = df_final.dropna(subset=['HDI', 'Suicide Rate', 'Region', 'Income Group'])\n",
    "df_2021 = df_final[df_final['Year'] == 2021].copy()\n",
    "print(f\"Data 2021 siap (total {len(df_2021)} negara).\")\n",
    "\n",
    "\n",
    "# --- 4. Create Plot 1 (Boxplot) - LABEL HORIZONTAL ---\n",
    "try:\n",
    "    income_order = ['Low income', 'Lower middle income', 'Upper middle income', 'High income']\n",
    "\n",
    "    base_plot1 = alt.Chart(df_2021).encode(\n",
    "        # --- PERBAIKAN DI SINI: labelAngle=0 ---\n",
    "        x=alt.X('Income Group',\n",
    "                sort=income_order,\n",
    "                title='Income Group',\n",
    "                axis=alt.Axis(labelAngle=0) # Paksa label jadi horizontal\n",
    "               ),\n",
    "        y=alt.Y('Suicide Rate', title='Suicide Rate (per 100k)')\n",
    "    )\n",
    "\n",
    "    # Layer 1: Boxplot (di tengah, lebih tipis)\n",
    "    boxplot_layer = base_plot1.mark_boxplot(\n",
    "        size=30,\n",
    "        opacity=0.6,\n",
    "        outliers=True\n",
    "    )\n",
    "\n",
    "    # Layer 2: Points (diperkecil dan digeser ke kanan)\n",
    "    points_layer = base_plot1.mark_point(\n",
    "        filled=True,\n",
    "        size=20,\n",
    "        opacity=0.7,\n",
    "        xOffset=25 # Geser ke kanan\n",
    "    ).encode(\n",
    "        color=alt.Color('Region', title='Continent')\n",
    "    )\n",
    "\n",
    "    chart1 = (boxplot_layer + points_layer).properties(\n",
    "        title='Suicide Rate by Income Group and Continent (2021)',\n",
    "        width=600,\n",
    "        height=400 # Mungkin perlu disesuaikan jika labelnya jadi mepet\n",
    "    )\n",
    "\n",
    "    chart1_file = 'slide1_boxplot_STATIC_horizontal.json'\n",
    "    chart1.save(chart1_file)\n",
    "    print(f\"Success: Boxplot (Label Horizontal) disimpan ke {chart1_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error membuat Chart 1 (Boxplot): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c7f27dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script Plot 1: Boxplot Time Series (Versi PLOTLY) ---\n",
      "Berhasil memuat dataset_master_lengkap.csv dan WDICountry.csv\n",
      "Berhasil menggabungkan data master dengan metadata (Region & Income Group).\n",
      "Semua kolom (termasuk Region & Income Group) ditemukan.\n",
      "Data 2019-2021 (dengan Region & Income) siap untuk di-plot.\n",
      "Membuat plot Plotly...\n",
      "\n",
      "--- BERHASIL (HTML) ---\n",
      "Plot Boxplot INTERAKTIF (berwarna) disimpan ke: slide1_boxplot_TIMESERIES.html\n",
      "\n",
      "--- INFO (PNG Gagal) ---\n",
      "Gagal menyimpan PNG: \n",
      "Image export using the \"kaleido\" engine requires the Kaleido package,\n",
      "which can be installed using pip:\n",
      "\n",
      "    $ pip install --upgrade kaleido\n",
      "\n",
      "Pastikan 'kaleido' sudah ter-install: pip install kaleido\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Mengatur 'template' default agar background-nya putih\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "print(\"--- Memulai script Plot 1: Boxplot Time Series (Versi PLOTLY) ---\")\n",
    "\n",
    "# --- 1. Tentukan Nama File ---\n",
    "file_master = 'dataset_master_lengkap.csv'\n",
    "file_metadata = 'WDICountry.csv' # File metadata untuk data 'Region' & 'Income Group'\n",
    "\n",
    "# --- 2. Muat Data ---\n",
    "try:\n",
    "    df_master = pd.read_csv(file_master)\n",
    "    df_meta = pd.read_csv(file_metadata)\n",
    "    print(f\"Berhasil memuat {file_master} dan {file_metadata}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File tidak ditemukan. {e}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Gabungkan Data Master dengan Metadata ---\n",
    "# Siapkan metadata: ambil 'Table Name', 'Region', dan 'Income Group'\n",
    "df_meta_processed = df_meta[['Table Name', 'Region', 'Income Group']].dropna()\n",
    "\n",
    "# Gabungkan!\n",
    "df_with_meta = pd.merge(\n",
    "    df_master,\n",
    "    df_meta_processed,\n",
    "    left_on='Country Name',\n",
    "    right_on='Table Name',\n",
    "    how='left' \n",
    ")\n",
    "print(\"Berhasil menggabungkan data master dengan metadata (Region & Income Group).\")\n",
    "\n",
    "# --- 4. Proses Data ---\n",
    "col_rate = 'Suicide Rate'\n",
    "col_year = 'Year'\n",
    "col_country = 'Country Name'\n",
    "col_region = 'Region'\n",
    "col_income = 'Income Group'\n",
    "\n",
    "# Cek apakah semua kolom ada\n",
    "required_cols = [col_rate, col_year, col_country, col_region, col_income]\n",
    "if not all(col in df_with_meta.columns for col in required_cols):\n",
    "    print(f\"Error: Gagal menggabungkan atau kolom tidak ditemukan.\")\n",
    "    print(f\"Kolom yang ada: {df_with_meta.columns.tolist()}\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"Semua kolom (termasuk Region & Income Group) ditemukan.\")\n",
    "\n",
    "# Filter hanya tahun yang kita mau\n",
    "years_to_plot = [2019, 2020, 2021]\n",
    "df_filtered = df_with_meta[df_with_meta[col_year].isin(years_to_plot)].copy()\n",
    "\n",
    "# Bersihkan data\n",
    "df_filtered = df_filtered.dropna(subset=[col_rate, col_income, col_region])\n",
    "\n",
    "# Tentukan urutan kategori Income Group\n",
    "income_order = ['Low income', 'Lower middle income', 'Upper middle income', 'High income']\n",
    "# Ubah jadi tipe 'category' agar urutannya benar di plot\n",
    "df_filtered[col_income] = pd.Categorical(df_filtered[col_income], categories=income_order, ordered=True)\n",
    "\n",
    "if df_filtered.empty:\n",
    "    print(\"Error: Tidak ada data valid untuk tahun 2019-2021 setelah dibersihkan.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Data 2019-2021 (dengan Region & Income) siap untuk di-plot.\")\n",
    "\n",
    "\n",
    "# --- 5. Buat Visualisasi (Plotly Boxplot + Slider + Warna) ---\n",
    "try:\n",
    "    print(\"Membuat plot Plotly...\")\n",
    "    fig = px.box(\n",
    "        df_filtered,\n",
    "        x=col_income,\n",
    "        y=col_rate,\n",
    "        animation_frame=\"Year\",     # Slider Tahun\n",
    "        color=col_region,           # <-- Warna berdasarkan Benua\n",
    "        points='all',               # <-- Tampilkan semua titik (seperti di plot statis)\n",
    "        hover_name=\"Country Name\",\n",
    "        title=\"Suicide Rate by Income Group and Continent (2019-2021)\",\n",
    "        category_orders={col_income: income_order} # Pastikan urutan sumbu X benar\n",
    "    )\n",
    "    \n",
    "    # Atur label sumbu\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Income Group\",\n",
    "        yaxis_title=\"Suicide Rate (per 100k)\",\n",
    "        legend_title=\"Continent\" # Judul legenda\n",
    "    )\n",
    "    \n",
    "    # --- 6. Menyimpan Plot ---\n",
    "    \n",
    "    # Simpan sebagai HTML (Interaktif, Pasti Berhasil)\n",
    "    html_file = 'slide1_boxplot_TIMESERIES.html'\n",
    "    fig.write_html(html_file)\n",
    "    print(f\"\\n--- BERHASIL (HTML) ---\")\n",
    "    print(f\"Plot Boxplot INTERAKTIF (berwarna) disimpan ke: {html_file}\")\n",
    "\n",
    "    # Coba Simpan sebagai PNG (Statis)\n",
    "    try:\n",
    "        png_file = 'slide1_boxplot_TIMESERIES.png'\n",
    "        fig.write_image(png_file, width=1000, height=550)\n",
    "        print(f\"\\n--- BERHASIL (PNG) ---\")\n",
    "        print(f\"Gambar plot (PNG berwarna) berhasil disimpan ke: {png_file}\")\n",
    "    except ValueError as e_png:\n",
    "        print(f\"\\n--- INFO (PNG Gagal) ---\")\n",
    "        print(f\"Gagal menyimpan PNG: {e_png}\")\n",
    "        print(\"Pastikan 'kaleido' sudah ter-install: pip install kaleido\")\n",
    "        \n",
    "except Exception as e_fig:\n",
    "    print(f\"Error membuat Peta Plotly: {e_fig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd6e14",
   "metadata": {},
   "source": [
    "# slide 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ab83b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vega_datasets in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: pandas in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from vega_datasets) (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas->vega_datasets) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas->vega_datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas->vega_datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from pandas->vega_datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->vega_datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install vega_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "daf41a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script visualisasi Peta Dunia (Perbaikan) ---\n",
      "Data geografi peta dimuat.\n",
      "File suicide rate berhasil dimuat.\n",
      "Data suicide 2021 selesai diproses.\n",
      "\n",
      "--- BERHASIL ---\n",
      "Peta dunia interaktif berhasil disimpan ke: slide2_map_INTERACTIVE.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "# --- 1. Define File Names ---\n",
    "file_suicide = 'suicide-rate-by-country-2025.csv'\n",
    "print(\"--- Memulai script visualisasi Peta Dunia (Perbaikan) ---\")\n",
    "\n",
    "# --- 2. Load Data Peta ---\n",
    "# Memuat data geografi (outline negara)\n",
    "# Ini adalah data TopoJSON yang punya 'properties.name' (nama negara)\n",
    "countries_geom = alt.topo_feature(data.world_110m.url, 'countries')\n",
    "print(\"Data geografi peta dimuat.\")\n",
    "\n",
    "# --- 3. Load & Process Data Suicide ---\n",
    "try:\n",
    "    df_suicide_raw = pd.read_csv(file_suicide)\n",
    "    print(\"File suicide rate berhasil dimuat.\")\n",
    "except Exception as e:\n",
    "    print(f\"Gagal memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Proses data suicide (ambil data 2021)\n",
    "suicide_cols_to_melt = ['SuicideRateCountries_2021']\n",
    "if suicide_cols_to_melt[0] not in df_suicide_raw.columns:\n",
    "    print(\"Error: Kolom 'SuicideRateCountries_2021' tidak ditemukan.\")\n",
    "    exit()\n",
    "\n",
    "df_suicide_melted = df_suicide_raw.melt(id_vars=['country'],\n",
    "                                        value_vars=suicide_cols_to_melt,\n",
    "                                        var_name='Suicide_Indicator',\n",
    "                                        value_name='Suicide Rate')\n",
    "df_suicide_melted['Suicide Rate'] = pd.to_numeric(df_suicide_melted['Suicide Rate'], errors='coerce')\n",
    "# Penting: Hapus baris yang datanya NaN SETELAH konversi\n",
    "df_suicide_2021 = df_suicide_melted.dropna(subset=['Suicide Rate'])\n",
    "print(\"Data suicide 2021 selesai diproses.\")\n",
    "\n",
    "\n",
    "# --- 4. (DIHAPUS) ---\n",
    "# Tidak perlu merge manual. Kita akan pakai transform_lookup.\n",
    "\n",
    "\n",
    "# --- 5. Create Map Chart (Static Version) - DIPERBAIKI ---\n",
    "try:\n",
    "    chart_map = alt.Chart(countries_geom).mark_geoshape(\n",
    "        stroke='black', # Garis batas antar negara\n",
    "        strokeWidth=0.2\n",
    "    ).project(\n",
    "        type='equirectangular' # Tipe proyeksi peta\n",
    "    ).encode(\n",
    "        # Warnai negara berdasarkan 'Suicide Rate'\n",
    "        # Gunakan alt.condition (c kecil)\n",
    "        color=alt.condition(\n",
    "            \"!isValid(datum['Suicide Rate'])\",  # Tes: jika datanya tidak valid (null)\n",
    "            alt.value('#lightgray'),            # Nilai jika benar: abu-abu muda\n",
    "            \n",
    "            # Nilai jika salah (jika datanya ada):\n",
    "            alt.Color('Suicide Rate:Q',\n",
    "                      scale=alt.Scale(range='heatmap', domain=[0, 30]),\n",
    "                      legend=alt.Legend(title=\"Suicide Rate (per 100k)\")\n",
    "                     )\n",
    "        ),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('country:N', title='Country'),\n",
    "            alt.Tooltip('Suicide Rate:Q', title='Suicide Rate', format='.2f')\n",
    "        ]\n",
    "    ).transform_lookup(\n",
    "        lookup='properties.name', # Kunci di PETA (nama negara standar)\n",
    "        from_=alt.LookupData(df_suicide_2021, 'country', ['Suicide Rate', 'country'])\n",
    "    ).properties(\n",
    "        title='Global Suicide Rate (2021)',\n",
    "        width=800,\n",
    "        height=450\n",
    "    ).interactive() # Dibuat interaktif dengan tooltip\n",
    "\n",
    "    # Simpan sebagai file JSON (sekarang interaktif)\n",
    "    chart_file = 'slide2_map_INTERACTIVE.json'\n",
    "    chart_map.save(chart_file)\n",
    "    \n",
    "    print(f\"\\n--- BERHASIL ---\")\n",
    "    print(f\"Peta dunia interaktif berhasil disimpan ke: {chart_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error membuat Peta: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9dba17a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvega_datasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[32m      3\u001b[39m world_ids = data.world_110m()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[43mworld_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m))\n",
      "\u001b[31mKeyError\u001b[39m: 'name'"
     ]
    }
   ],
   "source": [
    "# Jalankan ini di komputermu (bukan di sini)\n",
    "from vega_datasets import data\n",
    "world_ids = data.world_110m()\n",
    "print(set(world_ids['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94b202ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script visualisasi Peta Dunia (dengan Terjemahan) ---\n",
      "Data geografi peta dimuat.\n",
      "File suicide rate berhasil dimuat.\n",
      "Data suicide 2021 selesai diproses.\n",
      "Menerjemahkan nama negara agar sesuai dengan peta...\n",
      "Penerjemahan selesai.\n",
      "\n",
      "--- BERHASIL ---\n",
      "Peta dunia (yang sudah diterjemahkan) berhasil disimpan ke: slide2_map_TRANSLATED.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "# --- 1. Define File Names ---\n",
    "file_suicide = 'suicide-rate-by-country-2025.csv'\n",
    "print(\"--- Memulai script visualisasi Peta Dunia (dengan Terjemahan) ---\")\n",
    "\n",
    "# --- 2. Load Data Peta ---\n",
    "countries_geom = alt.topo_feature(data.world_110m.url, 'countries')\n",
    "print(\"Data geografi peta dimuat.\")\n",
    "\n",
    "# --- 3. Load & Process Data Suicide ---\n",
    "try:\n",
    "    df_suicide_raw = pd.read_csv(file_suicide)\n",
    "    print(\"File suicide rate berhasil dimuat.\")\n",
    "except Exception as e:\n",
    "    print(f\"Gagal memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Proses data suicide (ambil data 2021)\n",
    "suicide_cols_to_melt = ['SuicideRateCountries_2021']\n",
    "if suicide_cols_to_melt[0] not in df_suicide_raw.columns:\n",
    "    print(\"Error: Kolom 'SuicideRateCountries_2021' tidak ditemukan.\")\n",
    "    exit()\n",
    "\n",
    "df_suicide_melted = df_suicide_raw.melt(id_vars=['country'],\n",
    "                                        value_vars=suicide_cols_to_melt,\n",
    "                                        var_name='Suicide_Indicator',\n",
    "                                        value_name='Suicide Rate')\n",
    "df_suicide_melted['Suicide Rate'] = pd.to_numeric(df_suicide_melted['Suicide Rate'], errors='coerce')\n",
    "df_suicide_2021 = df_suicide_melted.dropna(subset=['Suicide Rate']).copy()\n",
    "print(\"Data suicide 2021 selesai diproses.\")\n",
    "\n",
    "\n",
    "# --- 4. MEMPERBAIKI NAMA NEGARA (BAGIAN BARU) ---\n",
    "print(\"Menerjemahkan nama negara agar sesuai dengan peta...\")\n",
    "\n",
    "# Kamus untuk menerjemahkan nama di file-mu ke nama standar peta\n",
    "translation_dict = {\n",
    "    # NAMA DI FILE-MU  :  NAMA STANDAR DI PETA\n",
    "    'United States': 'United States of America',\n",
    "    'South Korea': 'Republic of Korea',\n",
    "    'North Korea': \"Dem. People's Republic of Korea\",\n",
    "    'Russia': 'Russian Federation',\n",
    "    'Congo (Kinshasa)': 'Democratic Republic of the Congo',\n",
    "    'Congo (Brazzaville)': 'Republic of the Congo',\n",
    "    'Czechia': 'Czech Republic',\n",
    "    'Vietnam': 'Viet Nam',\n",
    "    'Laos': \"Lao People's Democratic Republic\",\n",
    "    'Syria': 'Syrian Arab Republic',\n",
    "    'Brunei': 'Brunei Darussalam',\n",
    "    'Taiwan': 'Taiwan, Province of China',\n",
    "    'Serbia': 'Republic of Serbia',\n",
    "    'Macedonia': 'North Macedonia'\n",
    "    # Tambahkan lebih banyak terjemahan di sini jika perlu\n",
    "}\n",
    "\n",
    "# Buat kolom baru dengan nama yang sudah diterjemahkan\n",
    "# .replace() akan mengganti nama yang ada di kamus,\n",
    "# dan membiarkan nama yang lain (seperti \"Australia\") apa adanya.\n",
    "df_suicide_2021['country_translated'] = df_suicide_2021['country'].replace(translation_dict)\n",
    "print(\"Penerjemahan selesai.\")\n",
    "\n",
    "\n",
    "# --- 5. Create Map Chart (Menggunakan Nama yang Diterjemahkan) ---\n",
    "try:\n",
    "    chart_map = alt.Chart(countries_geom).mark_geoshape(\n",
    "        stroke='black',\n",
    "        strokeWidth=0.2\n",
    "    ).project(\n",
    "        type='equirectangular'\n",
    "    ).encode(\n",
    "        # Warnai peta\n",
    "        color=alt.condition(\n",
    "            \"!isValid(datum['Suicide Rate'])\",\n",
    "            alt.value('#lightgray'),\n",
    "            alt.Color('Suicide Rate:Q',\n",
    "                      scale=alt.Scale(range='heatmap', domain=[0, 30]),\n",
    "                      legend=alt.Legend(title=\"Suicide Rate (per 100k)\")\n",
    "                     )\n",
    "        ),\n",
    "        # Tooltip akan menampilkan nama asli dari file-mu\n",
    "        tooltip=[\n",
    "            alt.Tooltip('country:N', title='Country'),\n",
    "            alt.Tooltip('Suicide Rate:Q', title='Suicide Rate', format='.2f')\n",
    "        ]\n",
    "    ).transform_lookup(\n",
    "        # Cocokkan 'properties.name' di peta...\n",
    "        lookup='properties.name', \n",
    "        # ...dengan 'country_translated' di data kita\n",
    "        from_=alt.LookupData(df_suicide_2021, 'country_translated', ['Suicide Rate', 'country'])\n",
    "    ).properties(\n",
    "        title='Global Suicide Rate (2021)',\n",
    "        width=800,\n",
    "        height=450\n",
    "    ).interactive()\n",
    "\n",
    "    # Simpan sebagai file JSON\n",
    "    chart_file = 'slide2_map_TRANSLATED.json'\n",
    "    chart_map.save(chart_file)\n",
    "    \n",
    "    print(f\"\\n--- BERHASIL ---\")\n",
    "    print(f\"Peta dunia (yang sudah diterjemahkan) berhasil disimpan ke: {chart_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error membuat Peta: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9f3feaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script Peta Time Series (dengan Slider) ---\n",
      "Data geografi peta dimuat.\n",
      "File suicide rate berhasil dimuat.\n",
      "Data suicide berhasil di-MELT ke format 'panjang'.\n",
      "Menerjemahkan nama negara...\n",
      "Penerjemahan selesai.\n",
      "\n",
      "--- BERHASIL ---\n",
      "Peta dunia INTERAKTIF (dengan slider tahun) berhasil disimpan ke: slide2_map_TIMESERIES.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "# --- 1. Define File Names ---\n",
    "file_suicide = 'suicide-rate-by-country-2025.csv'\n",
    "print(\"--- Memulai script Peta Time Series (dengan Slider) ---\")\n",
    "\n",
    "# --- 2. Load Data Peta ---\n",
    "countries_geom = alt.topo_feature(data.world_110m.url, 'countries')\n",
    "print(\"Data geografi peta dimuat.\")\n",
    "\n",
    "# --- 3. Load & Process (Melt) Data Suicide ---\n",
    "try:\n",
    "    df_suicide_raw = pd.read_csv(file_suicide)\n",
    "    print(\"File suicide rate berhasil dimuat.\")\n",
    "except Exception as e:\n",
    "    print(f\"Gagal memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Kolom tahun yang akan di-Melt\n",
    "suicide_cols_to_melt = [\n",
    "    'SuicideRateCountries_2019',\n",
    "    'SuicideRateCountries_2020',\n",
    "    'SuicideRateCountries_2021'\n",
    "]\n",
    "# Cek apakah kolomnya ada\n",
    "existing_cols = [col for col in suicide_cols_to_melt if col in df_suicide_raw.columns]\n",
    "if not existing_cols:\n",
    "    print(f\"Error: Tidak ditemukan kolom data suicide (seperti 'SuicideRateCountries_2019')\")\n",
    "    exit()\n",
    "\n",
    "# Proses MELT\n",
    "df_suicide_long = df_suicide_raw.melt(\n",
    "    id_vars=['country'],\n",
    "    value_vars=existing_cols,\n",
    "    var_name='Indicator',\n",
    "    value_name='Suicide Rate'\n",
    ")\n",
    "\n",
    "# Ekstrak Tahun dari nama kolom\n",
    "df_suicide_long['Year'] = df_suicide_long['Indicator'].str.extract(r'(\\d{4})').astype(int)\n",
    "df_suicide_long['Suicide Rate'] = pd.to_numeric(df_suicide_long['Suicide Rate'], errors='coerce')\n",
    "df_suicide_final = df_suicide_long.dropna(subset=['Suicide Rate']).copy()\n",
    "print(\"Data suicide berhasil di-MELT ke format 'panjang'.\")\n",
    "\n",
    "\n",
    "# --- 4. Menerjemahkan Nama Negara ---\n",
    "print(\"Menerjemahkan nama negara...\")\n",
    "translation_dict = {\n",
    "    'United States': 'United States of America',\n",
    "    'South Korea': 'Republic of Korea',\n",
    "    'North Korea': \"Dem. People's Republic of Korea\",\n",
    "    'Russia': 'Russian Federation',\n",
    "    'Congo (Kinshasa)': 'Democratic Republic of the Congo',\n",
    "    'Congo (Brazzaville)': 'Republic of the Congo',\n",
    "    'Czechia': 'Czech Republic',\n",
    "    'Vietnam': 'Viet Nam',\n",
    "    'Laos': \"Lao People's Democratic Republic\",\n",
    "    'Syria': 'Syrian Arab Republic',\n",
    "    'Brunei': 'Brunei Darussalam',\n",
    "    'Taiwan': 'Taiwan, Province of China',\n",
    "    'Serbia': 'Republic of Serbia',\n",
    "    'Macedonia': 'North Macedonia'\n",
    "}\n",
    "df_suicide_final['country_translated'] = df_suicide_final['country'].replace(translation_dict)\n",
    "print(\"Penerjemahan selesai.\")\n",
    "\n",
    "\n",
    "# --- 5. Membuat Peta dengan Slider Tahun ---\n",
    "try:\n",
    "    # Buat Slider untuk Tahun\n",
    "    # Ambil tahun min dan max dari data\n",
    "    year_min = df_suicide_final['Year'].min()\n",
    "    year_max = df_suicide_final['Year'].max()\n",
    "    \n",
    "    slider = alt.binding_range(min=year_min, max=year_max, step=1, name='Year: ')\n",
    "    select_year = alt.selection_point(name=\"YearSelection\", fields=['Year'], bind=slider, value=year_max)\n",
    "\n",
    "    # Buat Peta\n",
    "    chart_map = alt.Chart(countries_geom).mark_geoshape(\n",
    "        stroke='black',\n",
    "        strokeWidth=0.2\n",
    "    ).project(\n",
    "        type='equirectangular'\n",
    "    ).encode(\n",
    "        # Warnai peta\n",
    "        color=alt.condition(\n",
    "            \"!isValid(datum['Suicide Rate'])\",\n",
    "            alt.value('#lightgray'),\n",
    "            alt.Color('Suicide Rate:Q',\n",
    "                      scale=alt.Scale(range='heatmap', domain=[0, 30]),\n",
    "                      legend=alt.Legend(title=\"Suicide Rate (per 100k)\")\n",
    "                     )\n",
    "        ),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('country:N', title='Country'),\n",
    "            alt.Tooltip('Year:O', title='Year'),\n",
    "            alt.Tooltip('Suicide Rate:Q', title='Suicide Rate', format='.2f')\n",
    "        ]\n",
    "    ).add_params(\n",
    "        select_year  # Tambahkan slider ke chart\n",
    "    ).transform_filter(\n",
    "        select_year  # Filter data peta berdasarkan tahun di slider\n",
    "    ).transform_lookup(\n",
    "        lookup='properties.name', \n",
    "        from_=alt.LookupData(df_suicide_final, 'country_translated', ['Suicide Rate', 'country', 'Year'])\n",
    "    ).properties(\n",
    "        title='Global Suicide Rate by Year',\n",
    "        width=800,\n",
    "        height=450\n",
    "    )\n",
    "\n",
    "    # Simpan sebagai file JSON\n",
    "    chart_file = 'slide2_map_TIMESERIES.json'\n",
    "    chart_map.save(chart_file)\n",
    "    \n",
    "    print(f\"\\n--- BERHASIL ---\")\n",
    "    print(f\"Peta dunia INTERAKTIF (dengan slider tahun) berhasil disimpan ke: {chart_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error membuat Peta: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a4e4945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- NAMA KOLOM YANG ADA DI DATA PETA ---\n",
      "Index(['_comment', 'year', 'fertility', 'life_expect', 'n_fertility',\n",
      "       'n_life_expect', 'country', 'p_fertility', 'p_life_expect'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from vega_datasets import data\n",
    "\n",
    "# 'data.countries()' memuat tabel data negara yang dipakai peta\n",
    "try:\n",
    "    df_map_names = data.countries()\n",
    "    print(\"--- NAMA KOLOM YANG ADA DI DATA PETA ---\")\n",
    "    print(df_map_names.columns)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Terjadi error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b6ba48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DAFTAR NAMA STANDAR DI PETA ---\n",
      "['Afghanistan', 'Argentina', 'Aruba', 'Australia', 'Austria', 'Bahamas', 'Bangladesh', 'Barbados', 'Belgium', 'Bolivia', 'Brazil', 'Canada', 'Chile', 'China', 'Colombia', 'Costa Rica', 'Croatia', 'Cuba', 'Dominican Republic', 'Ecuador', 'Egypt', 'El Salvador', 'Finland', 'France', 'Georgia', 'Germany', 'Greece', 'Grenada', 'Haiti', 'Hong Kong', 'Iceland', 'India', 'Indonesia', 'Iran', 'Iraq', 'Ireland', 'Israel', 'Italy', 'Jamaica', 'Japan', 'Kenya', 'Lebanon', 'Mexico', 'Netherlands', 'New Zealand', 'Nigeria', 'North Korea', 'Norway', 'Pakistan', 'Peru', 'Philippines', 'Poland', 'Portugal', 'Rwanda', 'Saudi Arabia', 'South Africa', 'South Korea', 'Spain', 'Switzerland', 'Turkey', 'United Kingdom', 'United States', 'Venezuela']\n",
      "\n",
      "Total nama standar: 63\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from vega_datasets import data\n",
    "\n",
    "# 'data.countries()' memuat tabel data negara yang dipakai peta\n",
    "try:\n",
    "    df_map_names = data.countries()\n",
    "    \n",
    "    # Ambil semua nama unik dari kolom 'country'\n",
    "    standard_names = sorted(list(set(df_map_names['country'])))\n",
    "    \n",
    "    print(\"--- DAFTAR NAMA STANDAR DI PETA ---\")\n",
    "    print(standard_names)\n",
    "    print(\"\\nTotal nama standar:\", len(standard_names))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Terjadi error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ceb8e6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script Peta Time Series (Kamus Final) ---\n",
      "Data geografi peta dimuat.\n",
      "File suicide rate berhasil dimuat.\n",
      "Data suicide berhasil di-MELT.\n",
      "Menerjemahkan nama negara agar sesuai dengan Peta Standar...\n",
      "Penerjemahan selesai.\n",
      "\n",
      "--- BERHASIL ---\n",
      "Peta dunia INTERAKTIF (Final) berhasil disimpan ke: slide2_map_TIMESERIES_FINAL.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "# --- 1. Define File Names ---\n",
    "file_suicide = 'suicide-rate-by-country-2025.csv'\n",
    "print(\"--- Memulai script Peta Time Series (Kamus Final) ---\")\n",
    "\n",
    "# --- 2. Load Data Peta ---\n",
    "countries_geom = alt.topo_feature(data.world_110m.url, 'countries')\n",
    "print(\"Data geografi peta dimuat.\")\n",
    "\n",
    "# --- 3. Load & Process (Melt) Data Suicide ---\n",
    "try:\n",
    "    df_suicide_raw = pd.read_csv(file_suicide)\n",
    "    print(\"File suicide rate berhasil dimuat.\")\n",
    "except Exception as e:\n",
    "    print(f\"Gagal memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Kolom tahun yang akan di-Melt\n",
    "suicide_cols_to_melt = [\n",
    "    'SuicideRateCountries_2019',\n",
    "    'SuicideRateCountries_2020',\n",
    "    'SuicideRateCountries_2021'\n",
    "]\n",
    "existing_cols = [col for col in suicide_cols_to_melt if col in df_suicide_raw.columns]\n",
    "if not existing_cols:\n",
    "    print(f\"Error: Tidak ditemukan kolom data suicide (seperti 'SuicideRateCountries_2019')\")\n",
    "    exit()\n",
    "\n",
    "# Proses MELT\n",
    "df_suicide_long = df_suicide_raw.melt(\n",
    "    id_vars=['country'],\n",
    "    value_vars=existing_cols,\n",
    "    var_name='Indicator',\n",
    "    value_name='Suicide Rate'\n",
    ")\n",
    "df_suicide_long['Year'] = df_suicide_long['Indicator'].str.extract(r'(\\d{4})').astype(int)\n",
    "df_suicide_long['Suicide Rate'] = pd.to_numeric(df_suicide_long['Suicide Rate'], errors='coerce')\n",
    "df_suicide_final = df_suicide_long.dropna(subset=['Suicide Rate']).copy()\n",
    "print(\"Data suicide berhasil di-MELT.\")\n",
    "\n",
    "\n",
    "# --- 4. Menerjemahkan Nama Negara (KAMUS YANG BENAR) ---\n",
    "print(\"Menerjemahkan nama negara agar sesuai dengan Peta Standar...\")\n",
    "# Ini adalah kamus yang mencocokkan nama umum\n",
    "# ke nama standar di 'properties.name' file peta 'world_110m'\n",
    "translation_dict = {\n",
    "    'United States': 'United States of America',\n",
    "    'South Korea': 'Republic of Korea',\n",
    "    'North Korea': \"Dem. People's Republic of Korea\",\n",
    "    'Russia': 'Russian Federation',\n",
    "    'Congo (Kinshasa)': 'Democratic Republic of the Congo',\n",
    "    'Congo (Brazzaville)': 'Republic of the Congo',\n",
    "    'Czechia': 'Czech Republic',\n",
    "    'Vietnam': 'Viet Nam',\n",
    "    'Laos': \"Lao People's Democratic Republic\",\n",
    "    'Syria': 'Syrian Arab Republic',\n",
    "    'Brunei': 'Brunei Darussalam',\n",
    "    'Taiwan': 'Taiwan', # Peta standar sering hanya menyebut 'Taiwan'\n",
    "    'Serbia': 'Republic of Serbia',\n",
    "    'Macedonia': 'North Macedonia',\n",
    "    'Bosnia and Herzegovina': 'Bosnia and Herz.',\n",
    "    'Dominican Republic': 'Dominican Rep.',\n",
    "    'Central African Republic': 'Central African Rep.',\n",
    "    'Equatorial Guinea': 'Eq. Guinea',\n",
    "    'Eswatini': 'eSwatini',\n",
    "    'South Sudan': 'S. Sudan',\n",
    "    'Western Sahara': 'W. Sahara'\n",
    "}\n",
    "\n",
    "df_suicide_final['country_translated'] = df_suicide_final['country'].replace(translation_dict)\n",
    "print(\"Penerjemahan selesai.\")\n",
    "\n",
    "\n",
    "# --- 5. Membuat Peta dengan Slider Tahun ---\n",
    "try:\n",
    "    year_min = df_suicide_final['Year'].min()\n",
    "    year_max = df_suicide_final['Year'].max()\n",
    "    \n",
    "    slider = alt.binding_range(min=year_min, max=year_max, step=1, name='Year: ')\n",
    "    select_year = alt.selection_point(name=\"YearSelection\", fields=['Year'], bind=slider, value=year_max)\n",
    "\n",
    "    chart_map = alt.Chart(countries_geom).mark_geoshape(\n",
    "        stroke='black',\n",
    "        strokeWidth=0.2\n",
    "    ).project(\n",
    "        type='equirectangular'\n",
    "    ).encode(\n",
    "        color=alt.condition(\n",
    "            \"!isValid(datum['Suicide Rate'])\",\n",
    "            alt.value('#lightgray'),\n",
    "            alt.Color('Suicide Rate:Q',\n",
    "                      scale=alt.Scale(range='heatmap', domain=[0, 30]),\n",
    "                      legend=alt.Legend(title=\"Suicide Rate (per 100k)\")\n",
    "                     )\n",
    "        ),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('country:N', title='Country (from your file)'),\n",
    "            alt.Tooltip('Year:O', title='Year'),\n",
    "            alt.Tooltip('Suicide Rate:Q', title='Suicide Rate', format='.2f')\n",
    "        ]\n",
    "    ).add_params(\n",
    "        select_year\n",
    "    ).transform_filter(\n",
    "        select_year\n",
    "    ).transform_lookup(\n",
    "        # Cocokkan 'properties.name' di peta...\n",
    "        lookup='properties.name', \n",
    "        # ...dengan 'country_translated' (nama yang sudah diterjemahkan)\n",
    "        from_=alt.LookupData(df_suicide_final, 'country_translated', ['Suicide Rate', 'country', 'Year'])\n",
    "    ).properties(\n",
    "        title='Global Suicide Rate by Year',\n",
    "        width=800,\n",
    "        height=450\n",
    "    ).interactive()\n",
    "\n",
    "    # Simpan sebagai file JSON\n",
    "    chart_file = 'slide2_map_TIMESERIES_FINAL.json'\n",
    "    chart_map.save(chart_file)\n",
    "    \n",
    "    print(f\"\\n--- BERHASIL ---\")\n",
    "    print(f\"Peta dunia INTERAKTIF (Final) berhasil disimpan ke: {chart_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error membuat Peta: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8273f332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script Peta (Tanpa Kamus Terjemahan) ---\n",
      "Data geografi peta dimuat.\n",
      "File suicide rate berhasil dimuat.\n",
      "Data suicide berhasil di-MELT.\n",
      "Tidak ada penerjemahan. Mencocokkan nama 'country' langsung...\n",
      "\n",
      "--- BERHASIL ---\n",
      "Peta dunia (Tanpa Terjemahan) berhasil disimpan ke: slide2_map_NO_TRANSLATION.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "# --- 1. Define File Names ---\n",
    "file_suicide = 'suicide-rate-by-country-2025.csv'\n",
    "print(\"--- Memulai script Peta (Tanpa Kamus Terjemahan) ---\")\n",
    "\n",
    "# --- 2. Load Data Peta ---\n",
    "countries_geom = alt.topo_feature(data.world_110m.url, 'countries')\n",
    "print(\"Data geografi peta dimuat.\")\n",
    "\n",
    "# --- 3. Load & Process (Melt) Data Suicide ---\n",
    "try:\n",
    "    df_suicide_raw = pd.read_csv(file_suicide)\n",
    "    print(\"File suicide rate berhasil dimuat.\")\n",
    "except Exception as e:\n",
    "    print(f\"Gagal memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Kolom tahun yang akan di-Melt\n",
    "suicide_cols_to_melt = [\n",
    "    'SuicideRateCountries_2019',\n",
    "    'SuicideRateCountries_2020',\n",
    "    'SuicideRateCountries_2021'\n",
    "]\n",
    "existing_cols = [col for col in suicide_cols_to_melt if col in df_suicide_raw.columns]\n",
    "if not existing_cols:\n",
    "    print(f\"Error: Tidak ditemukan kolom data suicide\")\n",
    "    exit()\n",
    "\n",
    "# Proses MELT\n",
    "df_suicide_long = df_suicide_raw.melt(\n",
    "    id_vars=['country'],\n",
    "    value_vars=existing_cols,\n",
    "    var_name='Indicator',\n",
    "    value_name='Suicide Rate'\n",
    ")\n",
    "df_suicide_long['Year'] = df_suicide_long['Indicator'].str.extract(r'(\\d{4})').astype(int)\n",
    "df_suicide_long['Suicide Rate'] = pd.to_numeric(df_suicide_long['Suicide Rate'], errors='coerce')\n",
    "df_suicide_final = df_suicide_long.dropna(subset=['Suicide Rate']).copy()\n",
    "print(\"Data suicide berhasil di-MELT.\")\n",
    "\n",
    "\n",
    "# --- 4. (LANGKAH PENERJEMAHAN DIHAPUS) ---\n",
    "print(\"Tidak ada penerjemahan. Mencocokkan nama 'country' langsung...\")\n",
    "\n",
    "\n",
    "# --- 5. Membuat Peta dengan Slider Tahun ---\n",
    "try:\n",
    "    year_min = df_suicide_final['Year'].min()\n",
    "    year_max = df_suicide_final['Year'].max()\n",
    "    \n",
    "    slider = alt.binding_range(min=year_min, max=year_max, step=1, name='Year: ')\n",
    "    select_year = alt.selection_point(name=\"YearSelection\", fields=['Year'], bind=slider, value=year_max)\n",
    "\n",
    "    chart_map = alt.Chart(countries_geom).mark_geoshape(\n",
    "        stroke='black',\n",
    "        strokeWidth=0.2\n",
    "    ).project(\n",
    "        type='equirectangular'\n",
    "    ).encode(\n",
    "        color=alt.condition(\n",
    "            \"!isValid(datum['Suicide Rate'])\",\n",
    "            alt.value('#lightgray'),\n",
    "            alt.Color('Suicide Rate:Q',\n",
    "                      scale=alt.Scale(range='heatmap', domain=[0, 30]),\n",
    "                      legend=alt.Legend(title=\"Suicide Rate (per 100k)\")\n",
    "                     )\n",
    "        ),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('country:N', title='Country (from your file)'),\n",
    "            alt.Tooltip('Year:O', title='Year'),\n",
    "            alt.Tooltip('Suicide Rate:Q', title='Suicide Rate', format='.2f')\n",
    "        ]\n",
    "    ).add_params(\n",
    "        select_year\n",
    "    ).transform_filter(\n",
    "        select_year\n",
    "    ).transform_lookup(\n",
    "        # Cocokkan 'properties.name' di peta...\n",
    "        lookup='properties.name', \n",
    "        # ...dengan 'country' (nama ASLI dari file-mu)\n",
    "        from_=alt.LookupData(df_suicide_final, 'country', ['Suicide Rate', 'country', 'Year'])\n",
    "    ).properties(\n",
    "        title='Global Suicide Rate by Year',\n",
    "        width=800,\n",
    "        height=450\n",
    "    ).interactive()\n",
    "\n",
    "    # Simpan sebagai file JSON\n",
    "    chart_file = 'slide2_map_NO_TRANSLATION.json'\n",
    "    chart_map.save(chart_file)\n",
    "    \n",
    "    print(f\"\\n--- BERHASIL ---\")\n",
    "    print(f\"Peta dunia (Tanpa Terjemahan) berhasil disimpan ke: {chart_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error membuat Peta: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "481d1953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Using cached plotly-6.3.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from plotly) (2.9.0)\n",
      "Requirement already satisfied: packaging in c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\lib\\site-packages (from plotly) (25.0)\n",
      "Using cached plotly-6.3.1-py3-none-any.whl (9.8 MB)\n",
      "Installing collected packages: plotly\n",
      "Successfully installed plotly-6.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b490556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script Peta (Cara Baru: Plotly) ---\n",
      "File suicide rate berhasil dimuat.\n",
      "Data suicide berhasil di-MELT.\n",
      "Membuat peta Plotly...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DARA OKTAVIANA\\AppData\\Local\\Temp\\ipykernel_23472\\2929094867.py:48: DeprecationWarning: The library used by the *country names* `locationmode` option is changing in an upcoming version. Country names in existing plots may not work in the new version. To ensure consistent behavior, consider setting `locationmode` to *ISO-3*.\n",
      "  fig = px.choropleth(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BERHASIL (HTML) ---\n",
      "Peta INTERAKTIF disimpan ke: slide2_map_plotly.html\n",
      "Kamu bisa buka file ini di browser (Chrome, Firefox, dll.)\n",
      "\n",
      "Error saat menyimpan PNG: \n",
      "Image export using the \"kaleido\" engine requires the Kaleido package,\n",
      "which can be installed using pip:\n",
      "\n",
      "    $ pip install --upgrade kaleido\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DARA OKTAVIANA\\AppData\\Local\\Temp\\ipykernel_23472\\2929094867.py:81: DeprecationWarning:\n",
      "\n",
      "\n",
      "Support for the 'engine' argument is deprecated and will be removed after September 2025.\n",
      "Kaleido will be the only supported engine at that time.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Mengatur 'template' default agar background-nya putih\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "print(\"--- Memulai script Peta (Cara Baru: Plotly) ---\")\n",
    "\n",
    "# --- 1. Define File Names ---\n",
    "file_suicide = 'suicide-rate-by-country-2025.csv'\n",
    "\n",
    "# --- 2. Load & Process (Melt) Data Suicide ---\n",
    "try:\n",
    "    df_suicide_raw = pd.read_csv(file_suicide)\n",
    "    print(\"File suicide rate berhasil dimuat.\")\n",
    "except Exception as e:\n",
    "    print(f\"Gagal memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Kolom tahun yang akan di-Melt\n",
    "suicide_cols_to_melt = [\n",
    "    'SuicideRateCountries_2019',\n",
    "    'SuicideRateCountries_2020',\n",
    "    'SuicideRateCountries_2021'\n",
    "]\n",
    "existing_cols = [col for col in suicide_cols_to_melt if col in df_suicide_raw.columns]\n",
    "if not existing_cols:\n",
    "    print(f\"Error: Tidak ditemukan kolom data suicide\")\n",
    "    exit()\n",
    "\n",
    "# Proses MELT\n",
    "df_suicide_long = df_suicide_raw.melt(\n",
    "    id_vars=['country'],\n",
    "    value_vars=existing_cols,\n",
    "    var_name='Indicator',\n",
    "    value_name='Suicide Rate'\n",
    ")\n",
    "df_suicide_long['Year'] = df_suicide_long['Indicator'].str.extract(r'(\\d{4})').astype(int)\n",
    "df_suicide_long['Suicide Rate'] = pd.to_numeric(df_suicide_long['Suicide Rate'], errors='coerce')\n",
    "df_suicide_final = df_suicide_long.dropna(subset=['Suicide Rate']).copy()\n",
    "print(\"Data suicide berhasil di-MELT.\")\n",
    "\n",
    "\n",
    "# --- 3. Membuat Peta Plotly ---\n",
    "try:\n",
    "    print(\"Membuat peta Plotly...\")\n",
    "    fig = px.choropleth(\n",
    "        df_suicide_final,\n",
    "        locations=\"country\",            # Kolom di datamu yang berisi nama negara\n",
    "        locationmode=\"country names\",   # Beri tahu Plotly untuk mencocokkan nama\n",
    "        color=\"Suicide Rate\",           # Kolom untuk data warna\n",
    "        hover_name=\"country\",           # Apa yang muncul saat di-hover\n",
    "        animation_frame=\"Year\",         # Ini yang membuat SLIDER TAHUN\n",
    "        color_continuous_scale=px.colors.sequential.YlOrRd, # Skala warna (kuning ke merah)\n",
    "        projection=\"natural earth\",     # Tipe proyeksi peta\n",
    "        title=\"Global Suicide Rate by Year\"\n",
    "    )\n",
    "    \n",
    "    # Memperbarui layout legenda\n",
    "    fig.update_layout(\n",
    "        coloraxis_colorbar=dict(\n",
    "            title=\"Suicide Rate<br>(per 100k)\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # --- 4. Menyimpan Peta ---\n",
    "    \n",
    "    # Cara 1: Simpan sebagai HTML (Interaktif, Pasti Berhasil)\n",
    "    html_file = 'slide2_map_plotly.html'\n",
    "    fig.write_html(html_file)\n",
    "    print(f\"\\n--- BERHASIL (HTML) ---\")\n",
    "    print(f\"Peta INTERAKTIF disimpan ke: {html_file}\")\n",
    "    print(\"Kamu bisa buka file ini di browser (Chrome, Firefox, dll.)\")\n",
    "\n",
    "    # Cara 2: Coba Simpan sebagai PNG (Statis)\n",
    "    # Ini butuh library 'kaleido'. Mungkin gagal.\n",
    "    try:\n",
    "        png_file = 'slide2_map_plotly.png'\n",
    "        # engine='kaleido' adalah default, tapi kita tulis agar jelas\n",
    "        fig.write_image(png_file, width=1000, height=500, engine='kaleido')\n",
    "        print(f\"\\n--- BERHASIL (PNG) ---\")\n",
    "        print(f\"Gambar peta (PNG) berhasil disimpan ke: {png_file}\")\n",
    "    except ImportError:\n",
    "        print(\"\\n--- INFO (PNG Gagal) ---\")\n",
    "        print(\"Gagal menyimpan PNG karena library 'kaleido' tidak ter-install di environment ini.\")\n",
    "        print(\"Tapi jangan khawatir, file HTML-nya sudah 100% berhasil dibuat.\")\n",
    "    except Exception as e_png:\n",
    "        print(f\"\\nError saat menyimpan PNG: {e_png}\")\n",
    "        \n",
    "except Exception as e_fig:\n",
    "    print(f\"Error membuat Peta Plotly: {e_fig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c9aced",
   "metadata": {},
   "source": [
    "# 3. DATA GLOBAL 3 TAHUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b83046db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script Plot 1: Tren Global 3 Tahun ---\n",
      "Berhasil memuat dataset_gabungan_final.csv\n",
      "Data rata-rata global per tahun:\n",
      "   Year  Suicide Rate\n",
      "0  2019      9.440110\n",
      "1  2020     13.675419\n",
      "2  2021      9.510985\n",
      "\n",
      "--- BERHASIL ---\n",
      "Grafik Tren Global berhasil disimpan ke: slide3_global_trend.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# --- 1. Tentukan Nama File ---\n",
    "# Ini adalah file gabungan \"master\" yang sudah kamu buat\n",
    "file_gabungan = 'dataset_gabungan_final.csv'\n",
    "\n",
    "print(\"--- Memulai script Plot 1: Tren Global 3 Tahun ---\")\n",
    "\n",
    "# --- 2. Muat Data Gabungan ---\n",
    "try:\n",
    "    df_gabungan = pd.read_csv(file_gabungan)\n",
    "    print(f\"Berhasil memuat {file_gabungan}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_gabungan}' tidak ditemukan.\")\n",
    "    print(\"Pastikan file itu ada di folder yang sama dengan script ini.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Proses Data ---\n",
    "# Kita hanya butuh kolom 'Year' dan 'Suicide Rate'\n",
    "if 'Year' not in df_gabungan.columns or 'Suicide Rate' not in df_gabungan.columns:\n",
    "    print(\"Error: Kolom 'Year' atau 'Suicide Rate' tidak ditemukan di file.\")\n",
    "    exit()\n",
    "\n",
    "# Hitung rata-rata global suicide rate untuk setiap tahun\n",
    "# 'groupby('Year')' -> Kelompokkan berdasarkan 2019, 2020, 2021\n",
    "# 'mean()' -> Ambil rata-ratanya\n",
    "# 'reset_index()' -> Ubah kembali jadi DataFrame yang rapi\n",
    "df_tren = df_gabungan.groupby('Year')['Suicide Rate'].mean().reset_index()\n",
    "\n",
    "print(\"Data rata-rata global per tahun:\")\n",
    "print(df_tren.head())\n",
    "\n",
    "# --- 4. Buat Visualisasi (Line Chart) ---\n",
    "try:\n",
    "    chart = alt.Chart(df_tren).mark_line(\n",
    "        point=True,  # Tampilkan titik di setiap tahun\n",
    "        strokeWidth=3 # Tebalkan garis\n",
    "    ).encode(\n",
    "        # Sumbu X: Tahun. 'O' = Ordinal (kategorikal), bukan angka\n",
    "        x=alt.X('Year:O', axis=alt.Axis(title='Year', labelAngle=0)),\n",
    "        \n",
    "        # Sumbu Y: Rata-rata Suicide Rate\n",
    "        y=alt.Y('Suicide Rate', axis=alt.Axis(title='Average Global Suicide Rate (per 100k)')),\n",
    "        \n",
    "        # Tooltip untuk interaktivitas\n",
    "        tooltip=[\n",
    "            alt.Tooltip('Year:O'),\n",
    "            alt.Tooltip('Suicide Rate', title='Average Rate', format='.2f') # Format 2 angka desimal\n",
    "        ]\n",
    "    ).properties(\n",
    "        title='Global Suicide Rate Trend (2019-2021)',\n",
    "        width=500\n",
    "    ).interactive()\n",
    "\n",
    "    # Simpan sebagai file JSON\n",
    "    chart_file = 'slide3_global_trend.json'\n",
    "    chart.save(chart_file)\n",
    "    \n",
    "    print(f\"\\n--- BERHASIL ---\")\n",
    "    print(f\"Grafik Tren Global berhasil disimpan ke: {chart_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error saat membuat chart: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bcbbe7",
   "metadata": {},
   "source": [
    "# (Plot 2: Age vs Suicide - Per Tahun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a452865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script Plot 2: Age vs Suicide (Faceted by Year) ---\n",
      "Berhasil memuat dataset_gabungan_final.csv\n",
      "Error: Kolom berikut tidak ditemukan: SP.POP.65UP.TO.ZS\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['SP.POP.65UP.TO.ZS']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_23472\\211125911.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     33\u001b[39m years_to_plot = [\u001b[32m2019\u001b[39m, \u001b[32m2020\u001b[39m, \u001b[32m2021\u001b[39m]\n\u001b[32m     34\u001b[39m df_filtered = df_gabungan[df_gabungan[col_year].isin(years_to_plot)].copy()\n\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Bersihkan data, hapus baris yang datanya kosong untuk plot ini\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m df_filtered = df_filtered.dropna(subset=[col_age, col_rate])\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df_filtered.empty:\n\u001b[32m     40\u001b[39m     print(\u001b[33m\"Error: Tidak ada data valid untuk tahun 2019-2021 setelah dibersihkan.\"\u001b[39m)\n",
      "\u001b[32mc:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[39m\n\u001b[32m   6688\u001b[39m             ax = self._get_axis(agg_axis)\n\u001b[32m   6689\u001b[39m             indices = ax.get_indexer_for(subset)\n\u001b[32m   6690\u001b[39m             check = indices == -\u001b[32m1\u001b[39m\n\u001b[32m   6691\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m check.any():\n\u001b[32m-> \u001b[39m\u001b[32m6692\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m KeyError(np.array(subset)[check].tolist())\n\u001b[32m   6693\u001b[39m             agg_obj = self.take(indices, axis=agg_axis)\n\u001b[32m   6694\u001b[39m \n\u001b[32m   6695\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m thresh \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
      "\u001b[31mKeyError\u001b[39m: ['SP.POP.65UP.TO.ZS']"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# --- 1. Tentukan Nama File ---\n",
    "file_gabungan = 'dataset_gabungan_final.csv'\n",
    "\n",
    "print(\"--- Memulai script Plot 2: Age vs Suicide (Faceted by Year) ---\")\n",
    "\n",
    "# --- 2. Muat Data Gabungan ---\n",
    "try:\n",
    "    df_gabungan = pd.read_csv(file_gabungan)\n",
    "    print(f\"Berhasil memuat {file_gabungan}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_gabungan}' tidak ditemukan.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Proses Data ---\n",
    "col_age = 'SP.POP.65UP.TO.ZS' # Kolom populasi 65+\n",
    "col_rate = 'Suicide Rate'\n",
    "col_year = 'Year'\n",
    "col_country = 'Country Name' # Untuk tooltip\n",
    "\n",
    "required_cols = [col_age, col_rate, col_year, col_country]\n",
    "missing_cols = [col for col in required_cols if col not in df_gabungan.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Error: Kolom berikut tidak ditemukan: {', '.join(missing_cols)}\")\n",
    "    exit()\n",
    "\n",
    "# Ambil data untuk 3 tahun\n",
    "years_to_plot = [2019, 2020, 2021]\n",
    "df_filtered = df_gabungan[df_gabungan[col_year].isin(years_to_plot)].copy()\n",
    "\n",
    "# Bersihkan data, hapus baris yang datanya kosong untuk plot ini\n",
    "df_filtered = df_filtered.dropna(subset=[col_age, col_rate])\n",
    "\n",
    "if df_filtered.empty:\n",
    "    print(\"Error: Tidak ada data valid untuk tahun 2019-2021 setelah dibersihkan.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Data 2019-2021 siap untuk di-plot (total {len(df_filtered)} data poin).\")\n",
    "\n",
    "# --- 4. Buat Visualisasi (Faceted Scatter Plot) ---\n",
    "try:\n",
    "    # Chart dasar\n",
    "    base = alt.Chart(df_filtered).encode(\n",
    "        x=alt.X(col_age, axis=alt.Axis(title='Population Ages 65+ (% of Total)')),\n",
    "        y=alt.Y(col_rate, axis=alt.Axis(title='Suicide Rate (per 100k)'))\n",
    "    )\n",
    "    \n",
    "    # Layer 1: Titik-titik scatter plot\n",
    "    scatter_points = base.mark_point(opacity=0.7, filled=True).encode(\n",
    "        tooltip=[\n",
    "            alt.Tooltip(col_country, title='Country'),\n",
    "            alt.Tooltip(col_year, title='Year'),\n",
    "            alt.Tooltip(col_age, title='Pop. 65+ (%)', format='.1f'),\n",
    "            alt.Tooltip(col_rate, title='Suicide Rate', format='.1f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Layer 2: Garis regresi (tren)\n",
    "    regression_line = base.transform_regression(\n",
    "        col_age, col_rate, method='linear'\n",
    "    ).mark_line(\n",
    "        color='red',\n",
    "        strokeWidth=2\n",
    "    )\n",
    "\n",
    "    # Gabungkan kedua layer\n",
    "    chart = (scatter_points + regression_line).properties(\n",
    "        title='Suicide Rate vs. Elderly Population (% 65+)',\n",
    "        width=250 # Buat tiap plot lebih kecil agar muat 3\n",
    "    ).interactive()\n",
    "\n",
    "    # --- INI BAGIAN KUNCINYA ---\n",
    "    # Susun chart berdasarkan kolom 'Year'\n",
    "    faceted_chart = chart.facet(\n",
    "        column=alt.Column('Year:O', header=alt.Header(titleOrient=\"bottom\", labelOrient=\"bottom\"))\n",
    "    ).resolve_scale(\n",
    "        y='shared' # Pastikan sumbu Y semua plot sama\n",
    "    )\n",
    "\n",
    "    # Simpan sebagai file JSON\n",
    "    chart_file = 'slide3_age_vs_suicide_faceted.json'\n",
    "    faceted_chart.save(chart_file)\n",
    "    \n",
    "    print(f\"\\n--- BERHASIL ---\")\n",
    "    print(f\"Grafik 'Age vs Suicide' (per tahun) berhasil disimpan ke: {chart_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error saat membuat chart: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d42fa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memeriksa Kolom di 'dataset_gabungan_final.csv' ---\n",
      "File berhasil dimuat.\n",
      "\n",
      "--- DAFTAR KOLOM YANG DITEMUKAN ---\n",
      "['Country Name', 'Year', 'SP.POP.0014.TO.ZS', 'SP.POP.1564.TO.ZS', 'HDI', 'Suicide Rate']\n",
      "\n",
      "Kolom yang mungkin berhubungan dengan 'Populasi': ['SP.POP.0014.TO.ZS', 'SP.POP.1564.TO.ZS']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1. Tentukan Nama File ---\n",
    "file_gabungan = 'dataset_gabungan_final.csv'\n",
    "\n",
    "print(\"--- Memeriksa Kolom di 'dataset_gabungan_final.csv' ---\")\n",
    "\n",
    "# --- 2. Muat Data dan Tampilkan Kolom ---\n",
    "try:\n",
    "    df_gabungan = pd.read_csv(file_gabungan)\n",
    "    print(\"File berhasil dimuat.\")\n",
    "    print(\"\\n--- DAFTAR KOLOM YANG DITEMUKAN ---\")\n",
    "    print(df_gabungan.columns.tolist())\n",
    "    \n",
    "    # Coba cari kolom yang mirip\n",
    "    potential_cols = [col for col in df_gabungan.columns if 'POP' in col or '65' in col]\n",
    "    if potential_cols:\n",
    "        print(f\"\\nKolom yang mungkin berhubungan dengan 'Populasi': {potential_cols}\")\n",
    "    else:\n",
    "        print(\"\\nTidak ditemukan kolom yang mengandung 'POP' or '65'.\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_gabungan}' tidak ditemukan.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd0a02d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semua file berhasil dibaca.\n",
      "Memproses data WDI...\n",
      "Data WDI selesai diproses.\n",
      "Memproses data HDI...\n",
      "Data HDI selesai diproses.\n",
      "Memproses data Suicide Rate...\n",
      "Data Suicide Rate selesai diproses.\n",
      "Menggabungkan semua data...\n",
      "Data berhasil digabungkan.\n",
      "\n",
      "--- SELESAI ---\n",
      "File master baru berhasil disimpan sebagai: dataset_master_lengkap.csv\n",
      "File ini sekarang berisi data WDI (termasuk 65+ dan Unemployment), HDI, dan Suicide Rate.\n",
      "\n",
      "5 baris pertama data gabungan:\n",
      "  Country Name  Year  SL.UEM.TOTL.ZS  SP.POP.0014.TO.ZS  SP.POP.1564.TO.ZS  \\\n",
      "0  Afghanistan  2019          11.185          44.576832          53.047015   \n",
      "1  Afghanistan  2020          11.710          44.224104          53.405162   \n",
      "2  Afghanistan  2021          11.994          43.908125          53.739325   \n",
      "3      Albania  2019          11.466          17.744292          68.007610   \n",
      "4      Albania  2020          11.690          17.521976          67.711020   \n",
      "\n",
      "   SP.POP.65UP.TO.ZS    HDI  Suicide Rate  \n",
      "0           2.376153  0.492          4.10  \n",
      "1           2.370734  0.488          3.63  \n",
      "2           2.352550  0.473          3.60  \n",
      "3          14.248099  0.800          4.30  \n",
      "4          14.767004  0.784          4.02  \n",
      "\n",
      "Info data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 498 entries, 0 to 497\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Country Name       498 non-null    object \n",
      " 1   Year               498 non-null    int64  \n",
      " 2   SL.UEM.TOTL.ZS     465 non-null    float64\n",
      " 3   SP.POP.0014.TO.ZS  498 non-null    float64\n",
      " 4   SP.POP.1564.TO.ZS  498 non-null    float64\n",
      " 5   SP.POP.65UP.TO.ZS  498 non-null    float64\n",
      " 6   HDI                495 non-null    float64\n",
      " 7   Suicide Rate       491 non-null    float64\n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 31.3+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1. TENTUKAN NAMA FILE ---\n",
    "# !!! GANTI INI DENGAN NAMA FILE-MU YANG SEBENARNYA !!!\n",
    "file_wdi = 'WDICSV-rev.csv' \n",
    "file_hdi = 'human-development-index-(hdi)-by-country-2025.csv'\n",
    "file_suicide = 'suicide-rate-by-country-2025.csv'\n",
    "\n",
    "# Indikator WDI yang ingin kamu ambil\n",
    "wdi_indicators_to_keep = [\n",
    "    'SP.POP.0014.TO.ZS', # Populasi 0-14\n",
    "    'SP.POP.1564.TO.ZS', # Populasi 15-64\n",
    "    'SP.POP.65UP.TO.ZS', # Populasi 65+\n",
    "    'SL.UEM.TOTL.ZS'     # Unemployment Total\n",
    "]\n",
    "\n",
    "# Rentang tahun utama untuk analisis\n",
    "years_to_keep = [2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "# --- 2. MEMBACA SEMUA FILE ---\n",
    "try:\n",
    "    df_wdi_raw = pd.read_csv(file_wdi)\n",
    "    df_hdi_raw = pd.read_csv(file_hdi)\n",
    "    df_suicide_raw = pd.read_csv(file_suicide)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File tidak ditemukan. Pastikan nama file sudah benar.\")\n",
    "    print(e)\n",
    "    exit()\n",
    "\n",
    "print(\"Semua file berhasil dibaca.\")\n",
    "\n",
    "# --- 3. PROSES DATA WDICSV ---\n",
    "print(\"Memproses data WDI...\")\n",
    "df_wdi_filtered = df_wdi_raw[df_wdi_raw['Indicator Code'].isin(wdi_indicators_to_keep)].copy()\n",
    "id_vars_wdi = ['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code']\n",
    "value_vars_wdi = [col for col in df_wdi_filtered.columns if col not in id_vars_wdi]\n",
    "df_wdi_melted = df_wdi_filtered.melt(id_vars=id_vars_wdi,\n",
    "                                   value_vars=value_vars_wdi,\n",
    "                                   var_name='Year',\n",
    "                                   value_name='Value')\n",
    "df_wdi_melted['Year'] = pd.to_numeric(df_wdi_melted['Year'], errors='coerce')\n",
    "df_wdi_melted = df_wdi_melted.dropna(subset=['Year'])\n",
    "df_wdi_melted['Year'] = df_wdi_melted['Year'].astype(int)\n",
    "df_wdi_melted = df_wdi_melted[df_wdi_melted['Year'].isin(years_to_keep)]\n",
    "df_wdi_processed = df_wdi_melted.pivot_table(index=['Country Name', 'Year'],\n",
    "                                           columns='Indicator Code',\n",
    "                                           values='Value').reset_index()\n",
    "df_wdi_processed.columns.name = None\n",
    "print(\"Data WDI selesai diproses.\")\n",
    "\n",
    "# --- 4. PROSES DATA HDI ---\n",
    "print(\"Memproses data HDI...\")\n",
    "hdi_cols_to_melt = [\n",
    "    'HumanDevelopmentIndex_2019',\n",
    "    'HumanDevelopmentIndex_2020',\n",
    "    'HumanDevelopmentIndex_2021',\n",
    "    'HumanDevelopmentIndex_2022',\n",
    "    'HumanDevelopmentIndex_2023'\n",
    "]\n",
    "hdi_cols_exist = [col for col in hdi_cols_to_melt if col in df_hdi_raw.columns]\n",
    "df_hdi_melted = df_hdi_raw.melt(id_vars=['country'],\n",
    "                                value_vars=hdi_cols_exist,\n",
    "                                var_name='Indicator',\n",
    "                                value_name='HDI')\n",
    "df_hdi_melted['Year'] = df_hdi_melted['Indicator'].str.extract(r'(\\d{4})').astype(int)\n",
    "df_hdi_processed = df_hdi_melted.rename(columns={'country': 'Country Name'})\n",
    "df_hdi_processed = df_hdi_processed[['Country Name', 'Year', 'HDI']]\n",
    "print(\"Data HDI selesai diproses.\")\n",
    "\n",
    "# --- 5. PROSES DATA SUICIDE RATE ---\n",
    "print(\"Memproses data Suicide Rate...\")\n",
    "suicide_cols_to_melt = [\n",
    "    'SuicideRateCountries_2019',\n",
    "    'SuicideRateCountries_2020',\n",
    "    'SuicideRateCountries_2021'\n",
    "]\n",
    "suicide_cols_exist = [col for col in suicide_cols_to_melt if col in df_suicide_raw.columns]\n",
    "df_suicide_melted = df_suicide_raw.melt(id_vars=['country'],\n",
    "                                        value_vars=suicide_cols_exist,\n",
    "                                        var_name='Indicator',\n",
    "                                        value_name='Suicide Rate')\n",
    "df_suicide_melted['Year'] = df_suicide_melted['Indicator'].str.extract(r'(\\d{4})')\n",
    "df_suicide_melted['Year'] = pd.to_numeric(df_suicide_melted['Year']).astype(int)\n",
    "df_suicide_processed = df_suicide_melted.rename(columns={'country': 'Country Name'})\n",
    "df_suicide_processed = df_suicide_processed[['Country Name', 'Year', 'Suicide Rate']]\n",
    "print(\"Data Suicide Rate selesai diproses.\")\n",
    "\n",
    "# --- 6. GABUNGKAN (MERGE) SEMUA DATA ---\n",
    "# INI BAGIAN YANG HILANG\n",
    "print(\"Menggabungkan semua data...\")\n",
    "\n",
    "# Kita mulai dengan data WDI\n",
    "df_master = df_wdi_processed.copy()\n",
    "\n",
    "# Gabungkan dengan data HDI\n",
    "# 'how='inner'' berarti kita HANYA menyimpan baris yang ada di KEDUA tabel\n",
    "# (cocok berdasarkan 'Country Name' dan 'Year')\n",
    "df_master = pd.merge(df_master, df_hdi_processed, on=['Country Name', 'Year'], how='inner')\n",
    "\n",
    "# Gabungkan dengan data Suicide\n",
    "df_master = pd.merge(df_master, df_suicide_processed, on=['Country Name', 'Year'], how='inner')\n",
    "\n",
    "print(\"Data berhasil digabungkan.\")\n",
    "\n",
    "# --- 7. FINALISASI & SIMPAN CSV BARU ---\n",
    "# INI JUGA BAGIAN YANG HILANG\n",
    "\n",
    "# Data kita (2019-2021) sudah bersih karena 'how=inner'\n",
    "# Kita bisa langsung simpan\n",
    "output_file = 'dataset_master_lengkap.csv'\n",
    "df_master.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n--- SELESAI ---\")\n",
    "print(f\"File master baru berhasil disimpan sebagai: {output_file}\")\n",
    "print(\"File ini sekarang berisi data WDI (termasuk 65+ dan Unemployment), HDI, dan Suicide Rate.\")\n",
    "\n",
    "print(\"\\n5 baris pertama data gabungan:\")\n",
    "print(df_master.head())\n",
    "print(\"\\nInfo data:\")\n",
    "df_master.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ded7518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# --- 1. Tentukan Nama File ---\n",
    "# Ini adalah file master LENGKAP yang baru kita buat\n",
    "file_master = 'dataset_master_lengkap.csv'\n",
    "\n",
    "print(\"--- Memulai script Plot 2: Age vs Suicide (Faceted by Year) ---\")\n",
    "print(f\"Menggunakan file: {file_master}\")\n",
    "\n",
    "# --- 2. Muat Data Gabungan ---\n",
    "try:\n",
    "    df_master = pd.read_csv(file_master)\n",
    "    print(f\"Berhasil memuat {file_master}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_master}' tidak ditemukan.\")\n",
    "    print(\"Pastikan kamu sudah menjalankan script sebelumnya untuk membuat file ini.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Proses Data ---\n",
    "# Tentukan kolom yang kita butuhkan\n",
    "col_age = 'SP.POP.65UP.TO.ZS' # Kolom populasi 65+ (YANG SEKARANG SUDAH ADA)\n",
    "col_rate = 'Suicide Rate'\n",
    "col_year = 'Year'\n",
    "col_country = 'Country Name' # Untuk tooltip\n",
    "\n",
    "# Cek apakah semua kolom ada\n",
    "required_cols = [col_age, col_rate, col_year, col_country]\n",
    "missing_cols = [col for col in required_cols if col not in df_master.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Error: Kolom berikut tidak ditemukan di {file_master}: {', '.join(missing_cols)}\")\n",
    "    print(f\"Kolom yang ada: {df_master.columns.tolist()}\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"Semua kolom yang dibutuhkan (Age 65+, Suicide Rate, Year) ditemukan.\")\n",
    "\n",
    "# Ambil data untuk 3 tahun\n",
    "years_to_plot = [2019, 2020, 2021]\n",
    "df_filtered = df_master[df_master[col_year].isin(years_to_plot)].copy()\n",
    "\n",
    "# Bersihkan data, hapus baris yang datanya kosong untuk plot ini\n",
    "df_filtered = df_filtered.dropna(subset=[col_age, col_rate])\n",
    "\n",
    "if df_filtered.empty:\n",
    "    print(\"Error: Tidak ada data valid untuk tahun 2019-2021 setelah dibersihkan.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Data 2019-2021 siap untuk di-plot (total {len(df_filtered)} data poin).\")\n",
    "\n",
    "# --- 4. Buat Visualisasi (Faceted Scatter Plot) ---\n",
    "try:\n",
    "    # Chart dasar\n",
    "    base = alt.Chart(df_filtered).encode(\n",
    "        x=alt.X(col_age, axis=alt.Axis(title='Population Ages 65+ (% of Total)')),\n",
    "        y=alt.Y(col_rate, axis=alt.Axis(title='Suicide Rate (per 100k)'))\n",
    "    )\n",
    "    \n",
    "    # Layer 1: Titik-titik scatter plot\n",
    "    scatter_points = base.mark_point(opacity=0.7, filled=True).encode(\n",
    "        tooltip=[\n",
    "            alt.Tooltip(col_country, title='Country'),\n",
    "            alt.Tooltip(col_year, title='Year'),\n",
    "            alt.Tooltip(col_age, title='Pop. 65+ (%)', format='.1f'),\n",
    "            alt.Tooltip(col_rate, title='Suicide Rate', format='.1f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Layer 2: Garis regresi (tren)\n",
    "    regression_line = base.transform_regression(\n",
    "        col_age, col_rate, method='linear'\n",
    "    ).mark_line(\n",
    "        color='red',\n",
    "        strokeWidth=2\n",
    "    )\n",
    "\n",
    "    # Gabungkan kedua layer\n",
    "    chart = (scatter_points + regression_line).properties(\n",
    "        title='Suicide Rate vs. Elderly Population (% 65+)',\n",
    "        width=250 # Buat tiap plot lebih kecil agar muat 3\n",
    "    ).interactive()\n",
    "\n",
    "    # Susun chart berdasarkan kolom 'Year'\n",
    "    faceted_chart = chart.facet(\n",
    "        column=alt.Column('Year:O', header=alt.Header(titleOrient=\"bottom\", labelOrient=\"bottom\"))\n",
    "    ).resolve_scale(\n",
    "        y='shared' # Pastikan sumbu Y semua plot sama\n",
    "    )\n",
    "\n",
    "    # Simpan sebagai file JSON\n",
    "    chart_file = 'slide3_age_vs_suicide_faceted.json'\n",
    "    faceted_chart.save(chart_file)\n",
    "    \n",
    "    print(f\"\\n--- BERHASIL ---\")\n",
    "    print(f\"Grafik 'Age vs Suicide' (per tahun) berhasil disimpan ke: {chart_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error saat membuat chart: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ebac82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script Plot 2: Age vs Suicide (Grid 3x3 Lengkap) ---\n",
      "Menggunakan file: dataset_master_lengkap.csv\n",
      "Berhasil memuat dataset_master_lengkap.csv\n",
      "Semua kolom (3 Kelompok Usia, Suicide Rate, Year) ditemukan.\n",
      "Data 2019-2021 (3 kelompok usia) siap di-plot.\n",
      "\n",
      "--- BERHASIL ---\n",
      "Grafik Grid 3x3 'Age vs Suicide' (per tahun & usia) berhasil disimpan ke: slide3_age_vs_suicide_GRID_3x3.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\Lib\\site-packages\\altair\\utils\\core.py:384: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\Lib\\site-packages\\altair\\utils\\core.py:384: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\Lib\\site-packages\\altair\\utils\\core.py:384: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# --- 1. Tentukan Nama File ---\n",
    "file_master = 'dataset_master_lengkap.csv'\n",
    "\n",
    "print(\"--- Memulai script Plot 2: Age vs Suicide (Grid 3x3 Lengkap) ---\")\n",
    "print(f\"Menggunakan file: {file_master}\")\n",
    "\n",
    "# --- 2. Muat Data Gabungan ---\n",
    "try:\n",
    "    df_master = pd.read_csv(file_master)\n",
    "    print(f\"Berhasil memuat {file_master}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_master}' tidak ditemukan.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Proses Data (MELT Kolom Usia) ---\n",
    "col_rate = 'Suicide Rate'\n",
    "col_year = 'Year'\n",
    "col_country = 'Country Name'\n",
    "age_cols = ['SP.POP.0014.TO.ZS', 'SP.POP.1564.TO.ZS', 'SP.POP.65UP.TO.ZS']\n",
    "\n",
    "# Cek apakah semua kolom ada\n",
    "required_cols = age_cols + [col_rate, col_year, col_country]\n",
    "missing_cols = [col for col in required_cols if col not in df_master.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Error: Kolom berikut tidak ditemukan: {', '.join(missing_cols)}\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"Semua kolom (3 Kelompok Usia, Suicide Rate, Year) ditemukan.\")\n",
    "\n",
    "# 'Melt' data usia agar menjadi format \"panjang\"\n",
    "df_melted = df_master.melt(\n",
    "    id_vars=[col_country, col_year, col_rate],\n",
    "    value_vars=age_cols,\n",
    "    var_name='Age Group Indicator', # Ini akan berisi nama kolom (misal 'SP.POP.0014.TO.ZS')\n",
    "    value_name='Population Percentage' # Ini akan berisi nilainya (misal 15.2)\n",
    ")\n",
    "\n",
    "# Buat label yang lebih mudah dibaca\n",
    "age_rename_dict = {\n",
    "    'SP.POP.0014.TO.ZS': 'Ages 0-14',\n",
    "    'SP.POP.1564.TO.ZS': 'Ages 15-64 (Productive)',\n",
    "    'SP.POP.65UP.TO.ZS': 'Ages 65+ (Elderly)'\n",
    "}\n",
    "df_melted['Age Group'] = df_melted['Age Group Indicator'].map(age_rename_dict)\n",
    "\n",
    "# Filter hanya tahun yang kita mau\n",
    "years_to_plot = [2019, 2020, 2021]\n",
    "df_filtered = df_melted[df_melted[col_year].isin(years_to_plot)].copy()\n",
    "\n",
    "# Bersihkan data\n",
    "df_filtered = df_filtered.dropna(subset=['Population Percentage', col_rate])\n",
    "\n",
    "if df_filtered.empty:\n",
    "    print(\"Error: Tidak ada data valid setelah di-melt dan dibersihkan.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Data 2019-2021 (3 kelompok usia) siap di-plot.\")\n",
    "\n",
    "# --- 4. Buat Visualisasi (Faceted Grid 3x3) ---\n",
    "try:\n",
    "    # Chart dasar\n",
    "    base = alt.Chart(df_filtered).encode(\n",
    "        x=alt.X('Population Percentage:Q', axis=alt.Axis(title='Population (%)')),\n",
    "        y=alt.Y('Suicide Rate:Q', axis=alt.Axis(title='Suicide Rate'))\n",
    "    )\n",
    "    \n",
    "    # Layer 1: Titik-titik scatter plot\n",
    "    scatter_points = base.mark_point(opacity=0.6, filled=True).encode(\n",
    "        tooltip=[\n",
    "            alt.Tooltip(col_country, title='Country'),\n",
    "            alt.Tooltip(col_year, title='Year'),\n",
    "            alt.Tooltip('Age Group', title='Age Group'),\n",
    "            alt.Tooltip('Population Percentage', title='Pop. (%)', format='.1f'),\n",
    "            alt.Tooltip(col_rate, title='Suicide Rate', format='.1f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Layer 2: Garis regresi (tren)\n",
    "    regression_line = base.transform_regression(\n",
    "        'Population Percentage', col_rate, method='linear'\n",
    "    ).mark_line(\n",
    "        color='red',\n",
    "        strokeWidth=2\n",
    "    )\n",
    "\n",
    "    # Gabungkan kedua layer\n",
    "    chart = (scatter_points + regression_line).properties(\n",
    "        width=220, # Buat tiap plot lebih kecil\n",
    "        height=180\n",
    "    ).interactive()\n",
    "\n",
    "    # --- INI BAGIAN KUNCINYA (GRID 3x3) ---\n",
    "    faceted_chart = chart.facet(\n",
    "        # Buat 3 kolom, satu per TAHUN\n",
    "        column=alt.Column('Year:O', header=alt.Header(titleOrient=\"bottom\", labelOrient=\"bottom\")),\n",
    "        # Buat 3 baris, satu per KELOMPOK USIA\n",
    "        row=alt.Column('Age Group:N', header=alt.Header(titleOrient=\"left\", labelOrient=\"left\"))\n",
    "    ).resolve_scale(\n",
    "        y='shared' # Sumbu Y sama untuk semua plot\n",
    "    )\n",
    "\n",
    "    # Simpan sebagai file JSON\n",
    "    chart_file = 'slide3_age_vs_suicide_GRID_3x3.json'\n",
    "    faceted_chart.save(chart_file)\n",
    "    \n",
    "    print(f\"\\n--- BERHASIL ---\")\n",
    "    print(f\"Grafik Grid 3x3 'Age vs Suicide' (per tahun & usia) berhasil disimpan ke: {chart_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error saat membuat chart: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf972ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mencoba memuat 'slide3_age_vs_suicide_GRID_3x3.json'...\n",
      "File JSON berhasil dimuat.\n",
      "Mengonversi ke PNG...\n",
      "Konversi PNG berhasil.\n",
      "\n",
      "--- BERHASIL ---\n",
      "Plot Grid 3x3 Usia berhasil disimpan sebagai: slide3_age_vs_suicide_GRID_3x3.png\n"
     ]
    }
   ],
   "source": [
    "import vl_convert as vlc\n",
    "import json\n",
    "\n",
    "# Nama file JSON input (yang baru saja kamu buat)\n",
    "json_file_name = 'slide3_age_vs_suicide_GRID_3x3.json'\n",
    "\n",
    "# Nama file PNG output\n",
    "png_file_name = 'slide3_age_vs_suicide_GRID_3x3.png'\n",
    "\n",
    "print(f\"Mencoba memuat '{json_file_name}'...\")\n",
    "\n",
    "try:\n",
    "    # 1. Muat file JSON\n",
    "    with open(json_file_name, 'r') as f:\n",
    "        chart_json = json.load(f)\n",
    "    print(\"File JSON berhasil dimuat.\")\n",
    "\n",
    "    # 2. Konversi ke PNG\n",
    "    print(\"Mengonversi ke PNG...\")\n",
    "    png_data = vlc.vegalite_to_png(vl_spec=chart_json, scale=2) # scale=2 untuk resolusi lebih tinggi\n",
    "    print(\"Konversi PNG berhasil.\")\n",
    "\n",
    "    # 3. Simpan file PNG\n",
    "    with open(png_file_name, \"wb\") as f:\n",
    "        f.write(png_data)\n",
    "    \n",
    "    print(f\"\\n--- BERHASIL ---\")\n",
    "    print(f\"Plot Grid 3x3 Usia berhasil disimpan sebagai: {png_file_name}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File tidak ditemukan: '{json_file_name}'\")\n",
    "    print(\"Pastikan kamu sudah menjalankan script sebelumnya untuk membuat file JSON.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nTerjadi error: {e}\")\n",
    "    print(\"Pastikan kamu sudah menjalankan 'pip install vl-convert-python'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10f3deb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script Plot 2: Age vs Suicide (Versi Interaktif) ---\n",
      "Menggunakan file: dataset_master_lengkap.csv\n",
      "Berhasil memuat dataset_master_lengkap.csv\n",
      "Data 2019-2021 (3 kelompok usia) siap di-plot.\n",
      "Error saat membuat chart: module 'altair' has no attribute 'selection_point'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# --- 1. Tentukan Nama File ---\n",
    "file_master = 'dataset_master_lengkap.csv'\n",
    "\n",
    "print(\"--- Memulai script Plot 2: Age vs Suicide (Versi Interaktif) ---\")\n",
    "print(f\"Menggunakan file: {file_master}\")\n",
    "\n",
    "# --- 2. Muat Data Gabungan ---\n",
    "try:\n",
    "    df_master = pd.read_csv(file_master)\n",
    "    print(f\"Berhasil memuat {file_master}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_master}' tidak ditemukan.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Proses Data (MELT Kolom Usia) ---\n",
    "# (Langkah ini sama persis dengan kode 3x3 Grid sebelumnya)\n",
    "col_rate = 'Suicide Rate'\n",
    "col_year = 'Year'\n",
    "col_country = 'Country Name'\n",
    "age_cols = ['SP.POP.0014.TO.ZS', 'SP.POP.1564.TO.ZS', 'SP.POP.65UP.TO.ZS']\n",
    "\n",
    "required_cols = age_cols + [col_rate, col_year, col_country]\n",
    "if not all(col in df_master.columns for col in required_cols):\n",
    "    print(f\"Error: Tidak semua kolom ditemukan.\")\n",
    "    exit()\n",
    "\n",
    "df_melted = df_master.melt(\n",
    "    id_vars=[col_country, col_year, col_rate],\n",
    "    value_vars=age_cols,\n",
    "    var_name='Age Group Indicator',\n",
    "    value_name='Population Percentage'\n",
    ")\n",
    "\n",
    "age_rename_dict = {\n",
    "    'SP.POP.0014.TO.ZS': 'Ages 0-14',\n",
    "    'SP.POP.1564.TO.ZS': 'Ages 15-64 (Productive)',\n",
    "    'SP.POP.65UP.TO.ZS': 'Ages 65+ (Elderly)'\n",
    "}\n",
    "df_melted['Age Group'] = df_melted['Age Group Indicator'].map(age_rename_dict)\n",
    "\n",
    "years_to_plot = [2019, 2020, 2021]\n",
    "df_filtered = df_melted[df_melted[col_year].isin(years_to_plot)].copy()\n",
    "df_filtered = df_filtered.dropna(subset=['Population Percentage', col_rate])\n",
    "print(\"Data 2019-2021 (3 kelompok usia) siap di-plot.\")\n",
    "\n",
    "# --- 4. Buat Visualisasi (Interaktif dengan Slider & Dropdown) ---\n",
    "try:\n",
    "    # --- BUAT KONTROL INTERAKTIF ---\n",
    "    \n",
    "    # 1. Dropdown untuk Kelompok Usia\n",
    "    age_groups = list(age_rename_dict.values())\n",
    "    age_dropdown = alt.binding_select(options=age_groups, name='Age Group: ')\n",
    "    select_age = alt.selection_point(fields=['Age Group'], bind=age_dropdown, value=age_groups[2]) # Default ke 65+\n",
    "\n",
    "    # 2. Slider untuk Tahun\n",
    "    year_slider = alt.binding_range(min=2019, max=2021, step=1, name='Year: ')\n",
    "    select_year = alt.selection_point(fields=['Year'], bind=year_slider, value=2021) # Default ke 2021\n",
    "\n",
    "    # --- BUAT CHART ---\n",
    "    \n",
    "    # Chart dasar (disaring oleh dropdown & slider)\n",
    "    base = alt.Chart(df_filtered).add_params(\n",
    "        select_age,\n",
    "        select_year\n",
    "    ).transform_filter(\n",
    "        select_age\n",
    "    ).transform_filter(\n",
    "        select_year\n",
    "    ).encode(\n",
    "        x=alt.X('Population Percentage:Q', axis=alt.Axis(title='Population (%)')),\n",
    "        y=alt.Y('Suicide Rate:Q', axis=alt.Axis(title='Suicide Rate (per 100k)'))\n",
    "    )\n",
    "    \n",
    "    # Layer 1: Titik-titik scatter plot\n",
    "    scatter_points = base.mark_point(opacity=0.7, filled=True).encode(\n",
    "        tooltip=[\n",
    "            alt.Tooltip(col_country, title='Country'),\n",
    "            alt.Tooltip(col_year, title='Year'),\n",
    "            alt.Tooltip('Age Group', title='Age Group'),\n",
    "            alt.Tooltip('Population Percentage', title='Pop. (%)', format='.1f'),\n",
    "            alt.Tooltip(col_rate, title='Suicide Rate', format='.1f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Layer 2: Garis regresi (tren)\n",
    "    regression_line = base.transform_regression(\n",
    "        'Population Percentage', col_rate, method='linear'\n",
    "    ).mark_line(\n",
    "        color='red',\n",
    "        strokeWidth=2\n",
    "    )\n",
    "\n",
    "    # Gabungkan kedua layer dan tambahkan properti\n",
    "    chart = (scatter_points + regression_line).properties(\n",
    "        title='Suicide Rate vs. Population Demographics by Year',\n",
    "        width=600,\n",
    "        height=400\n",
    "    )\n",
    "\n",
    "    # Simpan sebagai file JSON\n",
    "    chart_file = 'slide3_age_vs_suicide_INTERACTIVE.json'\n",
    "    chart.save(chart_file)\n",
    "    \n",
    "    print(f\"\\n--- BERHASIL ---\")\n",
    "    print(f\"Grafik Interaktif 'Age vs Suicide' (dengan slider & dropdown) berhasil disimpan ke: {chart_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error saat membuat chart: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7ffdf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script Plot 2: Age vs Suicide (Perbaikan Versi Altair) ---\n",
      "Menggunakan file: dataset_master_lengkap.csv\n",
      "Berhasil memuat dataset_master_lengkap.csv\n",
      "Data 2019-2021 (3 kelompok usia) siap di-plot.\n",
      "Error saat membuat chart: Invalid specification\n",
      "\n",
      "        altair.vegalite.v4.schema.core.SelectionDef->1->bind, validating 'anyOf'\n",
      "\n",
      "        {'input': 'select', 'options': ['Ages 0-14', 'Ages 15-64 (Productive)', 'Ages 65+ (Elderly)'], 'name': 'Age Group: '} is not valid under any of the given schemas\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# --- 1. Tentukan Nama File ---\n",
    "file_master = 'dataset_master_lengkap.csv'\n",
    "\n",
    "print(\"--- Memulai script Plot 2: Age vs Suicide (Perbaikan Versi Altair) ---\")\n",
    "print(f\"Menggunakan file: {file_master}\")\n",
    "\n",
    "# --- 2. Muat Data Gabungan ---\n",
    "try:\n",
    "    df_master = pd.read_csv(file_master)\n",
    "    print(f\"Berhasil memuat {file_master}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_master}' tidak ditemukan.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Proses Data (MELT Kolom Usia) ---\n",
    "# (Langkah ini sama persis dengan kode 3x3 Grid sebelumnya)\n",
    "col_rate = 'Suicide Rate'\n",
    "col_year = 'Year'\n",
    "col_country = 'Country Name'\n",
    "age_cols = ['SP.POP.0014.TO.ZS', 'SP.POP.1564.TO.ZS', 'SP.POP.65UP.TO.ZS']\n",
    "\n",
    "required_cols = age_cols + [col_rate, col_year, col_country]\n",
    "if not all(col in df_master.columns for col in required_cols):\n",
    "    print(f\"Error: Tidak semua kolom ditemukan.\")\n",
    "    exit()\n",
    "\n",
    "df_melted = df_master.melt(\n",
    "    id_vars=[col_country, col_year, col_rate],\n",
    "    value_vars=age_cols,\n",
    "    var_name='Age Group Indicator',\n",
    "    value_name='Population Percentage'\n",
    ")\n",
    "\n",
    "age_rename_dict = {\n",
    "    'SP.POP.0014.TO.ZS': 'Ages 0-14',\n",
    "    'SP.POP.1564.TO.ZS': 'Ages 15-64 (Productive)',\n",
    "    'SP.POP.65UP.TO.ZS': 'Ages 65+ (Elderly)'\n",
    "}\n",
    "df_melted['Age Group'] = df_melted['Age Group Indicator'].map(age_rename_dict)\n",
    "\n",
    "years_to_plot = [2019, 2020, 2021]\n",
    "df_filtered = df_melted[df_melted[col_year].isin(years_to_plot)].copy()\n",
    "df_filtered = df_filtered.dropna(subset=['Population Percentage', col_rate])\n",
    "print(\"Data 2019-2021 (3 kelompok usia) siap di-plot.\")\n",
    "\n",
    "# --- 4. Buat Visualisasi (Interaktif dengan Slider & Dropdown) ---\n",
    "try:\n",
    "    # --- BUAT KONTROL INTERAKTIF ---\n",
    "    \n",
    "    # 1. Dropdown untuk Kelompok Usia\n",
    "    age_groups = list(age_rename_dict.values())\n",
    "    age_dropdown = alt.binding_select(options=age_groups, name='Age Group: ')\n",
    "    \n",
    "    # --- PERBAIKAN DI SINI ---\n",
    "    # Mengganti alt.selection_point -> alt.selection_single\n",
    "    select_age = alt.selection_single(fields=['Age Group'], bind=age_dropdown, value=age_groups[2])\n",
    "\n",
    "    # 2. Slider untuk Tahun\n",
    "    year_slider = alt.binding_range(min=2019, max=2021, step=1, name='Year: ')\n",
    "    \n",
    "    # --- PERBAIKAN DI SINI ---\n",
    "    # Mengganti alt.selection_point -> alt.selection_single\n",
    "    select_year = alt.selection_single(fields=['Year'], bind=year_slider, value=2021)\n",
    "\n",
    "    # --- BUAT CHART ---\n",
    "    \n",
    "    base = alt.Chart(df_filtered).add_params(\n",
    "        select_age,\n",
    "        select_year\n",
    "    ).transform_filter(\n",
    "        select_age\n",
    "    ).transform_filter(\n",
    "        select_year\n",
    "    ).encode(\n",
    "        x=alt.X('Population Percentage:Q', axis=alt.Axis(title='Population (%)')),\n",
    "        y=alt.Y('Suicide Rate:Q', axis=alt.Axis(title='Suicide Rate (per 100k)'))\n",
    "    )\n",
    "    \n",
    "    scatter_points = base.mark_point(opacity=0.7, filled=True).encode(\n",
    "        tooltip=[\n",
    "            alt.Tooltip(col_country, title='Country'),\n",
    "            alt.Tooltip(col_year, title='Year'),\n",
    "            alt.Tooltip('Age Group', title='Age Group'),\n",
    "            alt.Tooltip('Population Percentage', title='Pop. (%)', format='.1f'),\n",
    "            alt.Tooltip(col_rate, title='Suicide Rate', format='.1f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    regression_line = base.transform_regression(\n",
    "        'Population Percentage', col_rate, method='linear'\n",
    "    ).mark_line(\n",
    "        color='red',\n",
    "        strokeWidth=2\n",
    "    )\n",
    "\n",
    "    chart = (scatter_points + regression_line).properties(\n",
    "        title='Suicide Rate vs. Population Demographics by Year',\n",
    "        width=600,\n",
    "        height=400\n",
    "    )\n",
    "\n",
    "    # Simpan sebagai file JSON\n",
    "    chart_file = 'slide3_age_vs_suicide_INTERACTIVE.json'\n",
    "    chart.save(chart_file)\n",
    "    \n",
    "    print(f\"\\n--- BERHASIL ---\")\n",
    "    print(f\"Grafik Interaktif 'Age vs Suicide' (dengan slider & dropdown) berhasil disimpan ke: {chart_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error saat membuat chart: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d519d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script Plot 2: Age vs Suicide (Perbaikan v4 Final: add_selection) ---\n",
      "Menggunakan file: dataset_master_lengkap.csv\n",
      "Berhasil memuat dataset_master_lengkap.csv\n",
      "Data 2019-2021 (3 kelompok usia) siap di-plot.\n",
      "\n",
      "--- BERHASIL ---\n",
      "Grafik Interaktif 'Age vs Suicide' (dengan slider & dropdown) berhasil disimpan ke: slide3_age_vs_suicide_INTERACTIVE.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\Lib\\site-packages\\altair\\utils\\core.py:384: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\Lib\\site-packages\\altair\\utils\\core.py:384: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "c:\\software\\environments\\deep_learning\\environments\\deep_learning_cv\\Lib\\site-packages\\altair\\utils\\core.py:384: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# --- 1. Tentukan Nama File ---\n",
    "file_master = 'dataset_master_lengkap.csv'\n",
    "\n",
    "print(\"--- Memulai script Plot 2: Age vs Suicide (Perbaikan v4 Final: add_selection) ---\")\n",
    "print(f\"Menggunakan file: {file_master}\")\n",
    "\n",
    "# --- 2. Muat Data Gabungan ---\n",
    "try:\n",
    "    df_master = pd.read_csv(file_master)\n",
    "    print(f\"Berhasil memuat {file_master}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_master}' tidak ditemukan.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Proses Data (MELT Kolom Usia) ---\n",
    "col_rate = 'Suicide Rate'\n",
    "col_year = 'Year'\n",
    "col_country = 'Country Name'\n",
    "age_cols = ['SP.POP.0014.TO.ZS', 'SP.POP.1564.TO.ZS', 'SP.POP.65UP.TO.ZS']\n",
    "\n",
    "required_cols = age_cols + [col_rate, col_year, col_country]\n",
    "if not all(col in df_master.columns for col in required_cols):\n",
    "    print(f\"Error: Tidak semua kolom ditemukan.\")\n",
    "    exit()\n",
    "\n",
    "df_melted = df_master.melt(\n",
    "    id_vars=[col_country, col_year, col_rate],\n",
    "    value_vars=age_cols,\n",
    "    var_name='Age Group Indicator',\n",
    "    value_name='Population Percentage'\n",
    ")\n",
    "\n",
    "age_rename_dict = {\n",
    "    'SP.POP.0014.TO.ZS': 'Ages 0-14',\n",
    "    'SP.POP.1564.TO.ZS': 'Ages 15-64 (Productive)',\n",
    "    'SP.POP.65UP.TO.ZS': 'Ages 65+ (Elderly)'\n",
    "}\n",
    "df_melted['Age Group'] = df_melted['Age Group Indicator'].map(age_rename_dict)\n",
    "\n",
    "years_to_plot = [2019, 2020, 2021]\n",
    "df_filtered = df_melted[df_melted[col_year].isin(years_to_plot)].copy()\n",
    "df_filtered = df_filtered.dropna(subset=['Population Percentage', col_rate])\n",
    "print(\"Data 2019-2021 (3 kelompok usia) siap di-plot.\")\n",
    "\n",
    "# --- 4. Buat Visualisasi (Interaktif dengan Slider & Dropdown) ---\n",
    "try:\n",
    "    # --- BUAT KONTROL INTERAKTIF ---\n",
    "    \n",
    "    # 1. Dropdown untuk Kelompok Usia\n",
    "    age_groups = list(age_rename_dict.values())\n",
    "    age_dropdown = alt.binding_select(options=age_groups, name='Age Group: ')\n",
    "    \n",
    "    select_age = alt.selection_single(\n",
    "        fields=['Age Group'], \n",
    "        bind=age_dropdown, \n",
    "        init={'Age Group': age_groups[2]} # Default ke 65+\n",
    "    )\n",
    "\n",
    "    # 2. Slider untuk Tahun\n",
    "    year_slider = alt.binding_range(min=2019, max=2021, step=1, name='Year: ')\n",
    "    \n",
    "    select_year = alt.selection_single(\n",
    "        fields=['Year'], \n",
    "        bind=year_slider, \n",
    "        init={'Year': 2021} # Default ke 2021\n",
    "    )\n",
    "\n",
    "    # --- BUAT CHART ---\n",
    "    \n",
    "    # --- PERBAIKAN DI SINI (add_params -> add_selection) ---\n",
    "    base = alt.Chart(df_filtered).add_selection(\n",
    "        select_age,\n",
    "        select_year\n",
    "    ).transform_filter(\n",
    "        select_age\n",
    "    ).transform_filter(\n",
    "        select_year\n",
    "    ).encode(\n",
    "        x=alt.X('Population Percentage:Q', axis=alt.Axis(title='Population (%)')),\n",
    "        y=alt.Y('Suicide Rate:Q', axis=alt.Axis(title='Suicide Rate (per 100k)'))\n",
    "    )\n",
    "    \n",
    "    scatter_points = base.mark_point(opacity=0.7, filled=True).encode(\n",
    "        tooltip=[\n",
    "            alt.Tooltip(col_country, title='Country'),\n",
    "            alt.Tooltip(col_year, title='Year'),\n",
    "            alt.Tooltip('Age Group', title='Age Group'),\n",
    "            alt.Tooltip('Population Percentage', title='Pop. (%)', format='.1f'),\n",
    "            alt.Tooltip(col_rate, title='Suicide Rate', format='.1f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    regression_line = base.transform_regression(\n",
    "        'Population Percentage', col_rate, method='linear'\n",
    "    ).mark_line(\n",
    "        color='red',\n",
    "        strokeWidth=2\n",
    "    )\n",
    "\n",
    "    chart = (scatter_points + regression_line).properties(\n",
    "        title='Suicide Rate vs. Population Demographics by Year',\n",
    "        width=600,\n",
    "        height=400\n",
    "    )\n",
    "\n",
    "    # Simpan sebagai file JSON\n",
    "    chart_file = 'slide3_age_vs_suicide_INTERACTIVE.json'\n",
    "    chart.save(chart_file)\n",
    "    \n",
    "    print(f\"\\n--- BERHASIL ---\")\n",
    "    print(f\"Grafik Interaktif 'Age vs Suicide' (dengan slider & dropdown) berhasil disimpan ke: {chart_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error saat membuat chart: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1acb95e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script Plot 2: Age vs Suicide (Versi PLOTLY) ---\n",
      "Berhasil memuat dataset_master_lengkap.csv\n",
      "Data 2019-2021 (3 kelompok usia) siap di-plot.\n",
      "Membuat peta Plotly...\n",
      "\n",
      "--- BERHASIL (HTML) ---\n",
      "Plot INTERAKTIF disimpan ke: slide3_age_vs_suicide_INTERACTIVE.html\n",
      "Buka file ini di browser untuk melihat slider dan 3 plotnya.\n",
      "\n",
      "--- INFO (PNG Gagal) ---\n",
      "Gagal menyimpan PNG: \n",
      "Image export using the \"kaleido\" engine requires the Kaleido package,\n",
      "which can be installed using pip:\n",
      "\n",
      "    $ pip install --upgrade kaleido\n",
      "\n",
      "Ini biasanya karena 'kaleido' belum ter-install.\n",
      "Jalankan 'pip install kaleido' di terminalmu lalu coba lagi.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Mengatur 'template' default agar background-nya putih\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "print(\"--- Memulai script Plot 2: Age vs Suicide (Versi PLOTLY) ---\")\n",
    "\n",
    "# --- 1. Tentukan Nama File ---\n",
    "file_master = 'dataset_master_lengkap.csv'\n",
    "\n",
    "# --- 2. Muat Data Gabungan ---\n",
    "try:\n",
    "    df_master = pd.read_csv(file_master)\n",
    "    print(f\"Berhasil memuat {file_master}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_master}' tidak ditemukan.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Proses Data (MELT Kolom Usia) ---\n",
    "# (Langkah ini sama persis dengan kode 3x3 Grid sebelumnya)\n",
    "col_rate = 'Suicide Rate'\n",
    "col_year = 'Year'\n",
    "col_country = 'Country Name'\n",
    "age_cols = ['SP.POP.0014.TO.ZS', 'SP.POP.1564.TO.ZS', 'SP.POP.65UP.TO.ZS']\n",
    "\n",
    "required_cols = age_cols + [col_rate, col_year, col_country]\n",
    "if not all(col in df_master.columns for col in required_cols):\n",
    "    print(f\"Error: Tidak semua kolom ditemukan.\")\n",
    "    exit()\n",
    "\n",
    "df_melted = df_master.melt(\n",
    "    id_vars=[col_country, col_year, col_rate],\n",
    "    value_vars=age_cols,\n",
    "    var_name='Age Group Indicator',\n",
    "    value_name='Population Percentage'\n",
    ")\n",
    "\n",
    "age_rename_dict = {\n",
    "    'SP.POP.0014.TO.ZS': 'Ages 0-14',\n",
    "    'SP.POP.1564.TO.ZS': 'Ages 15-64 (Productive)',\n",
    "    'SP.POP.65UP.TO.ZS': 'Ages 65+ (Elderly)'\n",
    "}\n",
    "df_melted['Age Group'] = df_melted['Age Group Indicator'].map(age_rename_dict)\n",
    "\n",
    "years_to_plot = [2019, 2020, 2021]\n",
    "df_filtered = df_melted[df_melted[col_year].isin(years_to_plot)].copy()\n",
    "df_filtered = df_filtered.dropna(subset=['Population Percentage', col_rate])\n",
    "print(\"Data 2019-2021 (3 kelompok usia) siap di-plot.\")\n",
    "\n",
    "# --- 4. Buat Visualisasi (Plotly Facet + Slider) ---\n",
    "try:\n",
    "    print(\"Membuat peta Plotly...\")\n",
    "    fig = px.scatter(\n",
    "        df_filtered,\n",
    "        x=\"Population Percentage\",\n",
    "        y=\"Suicide Rate\",\n",
    "        animation_frame=\"Year\",         # Ini membuat SLIDER TAHUN\n",
    "        facet_row=\"Age Group\",          # Ini membuat 3 plot vertikal\n",
    "        trendline=\"ols\",                # Ini menambahkan garis regresi (linear)\n",
    "        hover_name=\"Country Name\",\n",
    "        title=\"Suicide Rate vs. Population Demographics by Year\"\n",
    "    )\n",
    "    \n",
    "    # Atur kategori urutan baris\n",
    "    fig.update_layout(\n",
    "        height=900, # Buat lebih tinggi agar 3 plot muat\n",
    "        xaxis_title=\"Population (%)\",\n",
    "        yaxis_title=\"Suicide Rate (per 100k)\"\n",
    "    )\n",
    "    # Ganti nama label facet\n",
    "    fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
    "    \n",
    "    # --- 5. Menyimpan Peta ---\n",
    "    \n",
    "    # Cara 1: Simpan sebagai HTML (Interaktif, Pasti Berhasil)\n",
    "    html_file = 'slide3_age_vs_suicide_INTERACTIVE.html'\n",
    "    fig.write_html(html_file)\n",
    "    print(f\"\\n--- BERHASIL (HTML) ---\")\n",
    "    print(f\"Plot INTERAKTIF disimpan ke: {html_file}\")\n",
    "    print(\"Buka file ini di browser untuk melihat slider dan 3 plotnya.\")\n",
    "\n",
    "    # Cara 2: Coba Simpan sebagai PNG (Statis)\n",
    "    try:\n",
    "        png_file = 'slide3_age_vs_suicide.png'\n",
    "        # Kamu harus install kaleido dulu: pip install kaleido\n",
    "        fig.write_image(png_file, width=800, height=1000)\n",
    "        print(f\"\\n--- BERHASIL (PNG) ---\")\n",
    "        print(f\"Gambar plot (PNG) berhasil disimpan ke: {png_file}\")\n",
    "    except ValueError as e_png:\n",
    "        print(f\"\\n--- INFO (PNG Gagal) ---\")\n",
    "        print(f\"Gagal menyimpan PNG: {e_png}\")\n",
    "        print(\"Ini biasanya karena 'kaleido' belum ter-install.\")\n",
    "        print(\"Jalankan 'pip install kaleido' di terminalmu lalu coba lagi.\")\n",
    "        \n",
    "except Exception as e_fig:\n",
    "    print(f\"Error membuat Peta Plotly: {e_fig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc0a74c",
   "metadata": {},
   "source": [
    "# 3. plot ke tiga yg undep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dbcc598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script Plot 3: Unemployment vs Suicide (Versi PLOTLY) ---\n",
      "Berhasil memuat dataset_master_lengkap.csv\n",
      "Semua kolom (Unemployment, Suicide Rate, Year) ditemukan.\n",
      "Data 2019-2021 siap untuk di-plot (total 465 data poin).\n",
      "Membuat plot Plotly...\n",
      "\n",
      "--- BERHASIL (HTML) ---\n",
      "Plot INTERAKTIF disimpan ke: slide3_unemployment_vs_suicide_INTERACTIVE.html\n",
      "Buka file ini di browser untuk melihat slider-nya.\n",
      "\n",
      "--- INFO (PNG Gagal) ---\n",
      "Gagal menyimpan PNG: \n",
      "Image export using the \"kaleido\" engine requires the Kaleido package,\n",
      "which can be installed using pip:\n",
      "\n",
      "    $ pip install --upgrade kaleido\n",
      "\n",
      "Ini biasanya karena 'kaleido' belum ter-install.\n",
      "Jalankan 'pip install kaleido' di terminalmu lalu coba lagi.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Mengatur 'template' default agar background-nya putih\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "print(\"--- Memulai script Plot 3: Unemployment vs Suicide (Versi PLOTLY) ---\")\n",
    "\n",
    "# --- 1. Tentukan Nama File ---\n",
    "file_master = 'dataset_master_lengkap.csv'\n",
    "\n",
    "# --- 2. Muat Data Gabungan ---\n",
    "try:\n",
    "    df_master = pd.read_csv(file_master)\n",
    "    print(f\"Berhasil memuat {file_master}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_master}' tidak ditemukan.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Proses Data ---\n",
    "col_unemployment = 'SL.UEM.TOTL.ZS' # Kolom Unemployment\n",
    "col_rate = 'Suicide Rate'\n",
    "col_year = 'Year'\n",
    "col_country = 'Country Name'\n",
    "\n",
    "# Cek apakah semua kolom ada\n",
    "required_cols = [col_unemployment, col_rate, col_year, col_country]\n",
    "if not all(col in df_master.columns for col in required_cols):\n",
    "    print(f\"Error: Tidak semua kolom ditemukan di {file_master}.\")\n",
    "    print(f\"Kolom yang ada: {df_master.columns.tolist()}\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"Semua kolom (Unemployment, Suicide Rate, Year) ditemukan.\")\n",
    "\n",
    "# Filter hanya tahun yang kita mau\n",
    "years_to_plot = [2019, 2020, 2021]\n",
    "df_filtered = df_master[df_master[col_year].isin(years_to_plot)].copy()\n",
    "\n",
    "# Bersihkan data, hapus baris yang datanya kosong untuk plot ini\n",
    "df_filtered = df_filtered.dropna(subset=[col_unemployment, col_rate])\n",
    "\n",
    "if df_filtered.empty:\n",
    "    print(\"Error: Tidak ada data valid untuk tahun 2019-2021 setelah dibersihkan.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Data 2019-2021 siap untuk di-plot (total {len(df_filtered)} data poin).\")\n",
    "\n",
    "\n",
    "# --- 4. Buat Visualisasi (Plotly Scatter + Slider) ---\n",
    "try:\n",
    "    print(\"Membuat plot Plotly...\")\n",
    "    fig = px.scatter(\n",
    "        df_filtered,\n",
    "        x=col_unemployment,\n",
    "        y=col_rate,\n",
    "        animation_frame=\"Year\",         # Ini membuat SLIDER TAHUN\n",
    "        trendline=\"ols\",                # Ini menambahkan garis regresi (linear)\n",
    "        hover_name=\"Country Name\",\n",
    "        title=\"Suicide Rate vs. Unemployment Rate by Year\"\n",
    "    )\n",
    "    \n",
    "    # Atur label sumbu\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Unemployment Rate (%)\",\n",
    "        yaxis_title=\"Suicide Rate (per 100k)\"\n",
    "    )\n",
    "    \n",
    "    # --- 5. Menyimpan Plot ---\n",
    "    \n",
    "    # Cara 1: Simpan sebagai HTML (Interaktif, Pasti Berhasil)\n",
    "    html_file = 'slide3_unemployment_vs_suicide_INTERACTIVE.html'\n",
    "    fig.write_html(html_file)\n",
    "    print(f\"\\n--- BERHASIL (HTML) ---\")\n",
    "    print(f\"Plot INTERAKTIF disimpan ke: {html_file}\")\n",
    "    print(\"Buka file ini di browser untuk melihat slider-nya.\")\n",
    "\n",
    "    # Cara 2: Coba Simpan sebagai PNG (Statis)\n",
    "    try:\n",
    "        png_file = 'slide3_unemployment_vs_suicide.png'\n",
    "        # Kamu harus install kaleido dulu: pip install kaleido\n",
    "        fig.write_image(png_file, width=900, height=500)\n",
    "        print(f\"\\n--- BERHASIL (PNG) ---\")\n",
    "        print(f\"Gambar plot (PNG) berhasil disimpan ke: {png_file}\")\n",
    "    except ValueError as e_png:\n",
    "        print(f\"\\n--- INFO (PNG Gagal) ---\")\n",
    "        print(f\"Gagal menyimpan PNG: {e_png}\")\n",
    "        print(\"Ini biasanya karena 'kaleido' belum ter-install.\")\n",
    "        print(\"Jalankan 'pip install kaleido' di terminalmu lalu coba lagi.\")\n",
    "        \n",
    "except Exception as e_fig:\n",
    "    print(f\"Error membuat Peta Plotly: {e_fig}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6b56000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script Plot 3: Unemployment (Versi Warna Benua) ---\n",
      "Berhasil memuat dataset_master_lengkap.csv dan WDICountry.csv\n",
      "Berhasil menggabungkan data master dengan metadata Region.\n",
      "Semua kolom (termasuk Region) ditemukan.\n",
      "Data 2019-2021 (dengan Region) siap untuk di-plot.\n",
      "Membuat plot Plotly...\n",
      "\n",
      "--- BERHASIL (HTML) ---\n",
      "Plot INTERAKTIF (berwarna) disimpan ke: slide3_unemployment_vs_suicide_WARNA.html\n",
      "\n",
      "--- INFO (PNG Gagal) ---\n",
      "Gagal menyimpan PNG: \n",
      "Image export using the \"kaleido\" engine requires the Kaleido package,\n",
      "which can be installed using pip:\n",
      "\n",
      "    $ pip install --upgrade kaleido\n",
      "\n",
      "Pastikan 'kaleido' sudah ter-install: pip install kaleido\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Mengatur 'template' default agar background-nya putih\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "print(\"--- Memulai script Plot 3: Unemployment (Versi Warna Benua) ---\")\n",
    "\n",
    "# --- 1. Tentukan Nama File ---\n",
    "file_master = 'dataset_master_lengkap.csv'\n",
    "file_metadata = 'WDICountry.csv' # File metadata untuk data 'Region'\n",
    "\n",
    "# --- 2. Muat Data ---\n",
    "try:\n",
    "    df_master = pd.read_csv(file_master)\n",
    "    df_meta = pd.read_csv(file_metadata)\n",
    "    print(f\"Berhasil memuat {file_master} dan {file_metadata}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File tidak ditemukan. {e}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Gabungkan Data Master dengan Metadata (untuk dapat 'Region') ---\n",
    "# Siapkan metadata: ambil kolom 'Table Name' (nama bersih) dan 'Region'\n",
    "df_meta_processed = df_meta[['Table Name', 'Region']].dropna()\n",
    "\n",
    "# Gabungkan!\n",
    "# 'Country Name' dari file master-mu\n",
    "# 'Table Name' dari file metadata\n",
    "df_with_region = pd.merge(\n",
    "    df_master,\n",
    "    df_meta_processed,\n",
    "    left_on='Country Name',\n",
    "    right_on='Table Name',\n",
    "    how='left' # 'left' = tetap simpan semua data suicide, walau ada yg ga cocok region-nya\n",
    ")\n",
    "print(\"Berhasil menggabungkan data master dengan metadata Region.\")\n",
    "\n",
    "# --- 4. Proses Data ---\n",
    "col_unemployment = 'SL.UEM.TOTL.ZS' # Kolom Unemployment\n",
    "col_rate = 'Suicide Rate'\n",
    "col_year = 'Year'\n",
    "col_country = 'Country Name'\n",
    "col_region = 'Region' # Kolom baru kita!\n",
    "\n",
    "# Cek apakah semua kolom ada\n",
    "required_cols = [col_unemployment, col_rate, col_year, col_country, col_region]\n",
    "if not all(col in df_with_region.columns for col in required_cols):\n",
    "    print(f\"Error: Gagal menggabungkan atau kolom tidak ditemukan.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"Semua kolom (termasuk Region) ditemukan.\")\n",
    "\n",
    "# Filter hanya tahun yang kita mau\n",
    "years_to_plot = [2019, 2020, 2021]\n",
    "df_filtered = df_with_region[df_with_region[col_year].isin(years_to_plot)].copy()\n",
    "\n",
    "# Bersihkan data, hapus baris yang datanya kosong untuk plot ini\n",
    "df_filtered = df_filtered.dropna(subset=[col_unemployment, col_rate, col_region])\n",
    "\n",
    "if df_filtered.empty:\n",
    "    print(\"Error: Tidak ada data valid untuk tahun 2019-2021 setelah dibersihkan.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Data 2019-2021 (dengan Region) siap untuk di-plot.\")\n",
    "\n",
    "\n",
    "# --- 5. Buat Visualisasi (Plotly Scatter + Slider + WARNA) ---\n",
    "try:\n",
    "    print(\"Membuat plot Plotly...\")\n",
    "    fig = px.scatter(\n",
    "        df_filtered,\n",
    "        x=col_unemployment,\n",
    "        y=col_rate,\n",
    "        animation_frame=\"Year\",         # Slider Tahun\n",
    "        trendline=\"ols\",                # Garis regresi\n",
    "        color=col_region,               # <-- INI YANG BARU: Warna berdasarkan Benua\n",
    "        hover_name=\"Country Name\",\n",
    "        title=\"Suicide Rate vs. Unemployment Rate by Year and Continent\"\n",
    "    )\n",
    "    \n",
    "    # Atur label sumbu\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Unemployment Rate (%)\",\n",
    "        yaxis_title=\"Suicide Rate (per 100k)\",\n",
    "        legend_title=\"Continent\" # Judul legenda\n",
    "    )\n",
    "    \n",
    "    # --- 6. Menyimpan Plot ---\n",
    "    \n",
    "    # Simpan sebagai HTML (Interaktif, Pasti Berhasil)\n",
    "    html_file = 'slide3_unemployment_vs_suicide_WARNA.html'\n",
    "    fig.write_html(html_file)\n",
    "    print(f\"\\n--- BERHASIL (HTML) ---\")\n",
    "    print(f\"Plot INTERAKTIF (berwarna) disimpan ke: {html_file}\")\n",
    "\n",
    "    # Coba Simpan sebagai PNG (Statis)\n",
    "    try:\n",
    "        png_file = 'slide3_unemployment_vs_suicide_WARNA.png'\n",
    "        fig.write_image(png_file, width=1000, height=550) # Dibuat lebih lebar untuk legenda\n",
    "        print(f\"\\n--- BERHASIL (PNG) ---\")\n",
    "        print(f\"Gambar plot (PNG berwarna) berhasil disimpan ke: {png_file}\")\n",
    "    except ValueError as e_png:\n",
    "        print(f\"\\n--- INFO (PNG Gagal) ---\")\n",
    "        print(f\"Gagal menyimpan PNG: {e_png}\")\n",
    "        print(\"Pastikan 'kaleido' sudah ter-install: pip install kaleido\")\n",
    "        \n",
    "except Exception as e_fig:\n",
    "    print(f\"Error membuat Peta Plotly: {e_fig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b78b5",
   "metadata": {},
   "source": [
    "# 1. Gender vs suicide rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d7b38f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai script Plot 4: Gender vs Suicide (Versi PLOTLY) ---\n",
      "Berhasil memuat suicide-rate-by-country-2025.csv\n",
      "Data suicide (Male/Female) berhasil di-MELT.\n",
      "Data rata-rata global per gender:\n",
      "   Year  Gender  Suicide Rate\n",
      "0  2019  Female      4.348352\n",
      "1  2019    Male     14.704420\n",
      "2  2020  Female      4.398670\n",
      "3  2020    Male     14.894187\n",
      "4  2021  Female      4.356010\n",
      "5  2021    Male     14.774039\n",
      "Membuat plot Plotly...\n",
      "\n",
      "--- BERHASIL (HTML) ---\n",
      "Plot INTERAKTIF disimpan ke: slide3_gender_vs_suicide_INTERACTIVE.html\n",
      "\n",
      "--- INFO (PNG Gagal) ---\n",
      "Gagal menyimpan PNG: \n",
      "Image export using the \"kaleido\" engine requires the Kaleido package,\n",
      "which can be installed using pip:\n",
      "\n",
      "    $ pip install --upgrade kaleido\n",
      "\n",
      "Pastikan 'kaleido' sudah ter-install: pip install kaleido\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Mengatur 'template' default agar background-nya putih\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "print(\"--- Memulai script Plot 4: Gender vs Suicide (Versi PLOTLY) ---\")\n",
    "\n",
    "# --- 1. Tentukan Nama File ---\n",
    "# Kita pakai file suicide ASLI, bukan file master\n",
    "file_suicide = 'suicide-rate-by-country-2025.csv'\n",
    "\n",
    "# --- 2. Muat Data ---\n",
    "try:\n",
    "    df_suicide_raw = pd.read_csv(file_suicide)\n",
    "    print(f\"Berhasil memuat {file_suicide}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_suicide}' tidak ditemukan.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Proses Data (Melt) ---\n",
    "# Tentukan kolom-kolom yang akan kita ambil\n",
    "cols_to_melt = [\n",
    "    'SuicideRateMaleCountries_2019', 'SuicideRateMaleCountries_2020', 'SuicideRateMaleCountries_2021',\n",
    "    'SuicideRateFemaleCountries_2019', 'SuicideRateFemaleCountries_2020', 'SuicideRateFemaleCountries_2021'\n",
    "]\n",
    "\n",
    "# Cek apakah kolomnya ada\n",
    "existing_cols = [col for col in cols_to_melt if col in df_suicide_raw.columns]\n",
    "if len(existing_cols) < 6:\n",
    "    print(f\"Error: Tidak semua kolom Male/Female ditemukan di file.\")\n",
    "    exit()\n",
    "\n",
    "# Proses MELT\n",
    "df_long = df_suicide_raw.melt(\n",
    "    id_vars=['country'],\n",
    "    value_vars=existing_cols,\n",
    "    var_name='Indicator',\n",
    "    value_name='Suicide Rate'\n",
    ")\n",
    "\n",
    "# --- 4. Ekstrak Info Tahun dan Gender ---\n",
    "# Ekstrak Tahun\n",
    "df_long['Year'] = df_long['Indicator'].str.extract(r'(\\d{4})').astype(int)\n",
    "\n",
    "# Ekstrak Gender\n",
    "# Buat fungsi untuk menentukan gender\n",
    "def get_gender(indicator_name):\n",
    "    if 'Male' in indicator_name:\n",
    "        return 'Male'\n",
    "    elif 'Female' in indicator_name:\n",
    "        return 'Female'\n",
    "    return 'Unknown'\n",
    "\n",
    "df_long['Gender'] = df_long['Indicator'].apply(get_gender)\n",
    "\n",
    "# Bersihkan data\n",
    "df_long['Suicide Rate'] = pd.to_numeric(df_long['Suicide Rate'], errors='coerce')\n",
    "df_final = df_long.dropna(subset=['Suicide Rate'])\n",
    "print(\"Data suicide (Male/Female) berhasil di-MELT.\")\n",
    "\n",
    "# --- 5. Hitung Rata-Rata Global per Gender per Tahun ---\n",
    "df_agg = df_final.groupby(['Year', 'Gender'])['Suicide Rate'].mean().reset_index()\n",
    "\n",
    "print(\"Data rata-rata global per gender:\")\n",
    "print(df_agg.head(6))\n",
    "\n",
    "\n",
    "# --- 6. Buat Visualisasi (Plotly Line Chart) ---\n",
    "try:\n",
    "    print(\"Membuat plot Plotly...\")\n",
    "    fig = px.line(\n",
    "        df_agg,\n",
    "        x=\"Year\",\n",
    "        y=\"Suicide Rate\",\n",
    "        color=\"Gender\",           # Ini akan membuat 2 garis (Male & Female)\n",
    "        markers=True,             # Tambahkan titik di tiap data poin\n",
    "        title=\"Global Suicide Rate by Gender (2019-2021)\"\n",
    "    )\n",
    "    \n",
    "    # Atur label sumbu\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Year\",\n",
    "        yaxis_title=\"Average Suicide Rate (per 100k)\",\n",
    "        legend_title=\"Gender\"\n",
    "    )\n",
    "    # Pastikan sumbu X hanya menampilkan 2019, 2020, 2021\n",
    "    fig.update_xaxes(tickmode='linear')\n",
    "    \n",
    "    # --- 7. Menyimpan Plot ---\n",
    "    \n",
    "    # Cara 1: Simpan sebagai HTML (Interaktif, Pasti Berhasil)\n",
    "    html_file = 'slide3_gender_vs_suicide_INTERACTIVE.html'\n",
    "    fig.write_html(html_file)\n",
    "    print(f\"\\n--- BERHASIL (HTML) ---\")\n",
    "    print(f\"Plot INTERAKTIF disimpan ke: {html_file}\")\n",
    "\n",
    "    # Cara 2: Coba Simpan sebagai PNG (Statis)\n",
    "    try:\n",
    "        png_file = 'slide3_gender_vs_suicide.png'\n",
    "        fig.write_image(png_file, width=800, height=500)\n",
    "        print(f\"\\n--- BERHASIL (PNG) ---\")\n",
    "        print(f\"Gambar plot (PNG) berhasil disimpan ke: {png_file}\")\n",
    "    except ValueError as e_png:\n",
    "        print(f\"\\n--- INFO (PNG Gagal) ---\")\n",
    "        print(f\"Gagal menyimpan PNG: {e_png}\")\n",
    "        print(\"Pastikan 'kaleido' sudah ter-install: pip install kaleido\")\n",
    "        \n",
    "except Exception as e_fig:\n",
    "    print(f\"Error membuat Peta Plotly: {e_fig}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432f6437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_cv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
